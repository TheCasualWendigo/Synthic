{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec8ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pescador\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a429bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger('gbsd')\n",
    "LOGGER.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b16da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c20fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdbf4a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88c156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD_VOLENVPER = 0\n",
    "CMD_DUTYLL = 1\n",
    "CMD_MSB = 2\n",
    "CMD_LSB = 3\n",
    "CMD_COUNT = 4\n",
    "\n",
    "def onehot_cmd(data):\n",
    "    cmd = data[CMD_OFFSET]\n",
    "    nd = [ 0, 0, 0, 0 ]\n",
    "    nd[int(cmd)] = 1\n",
    "    return nd\n",
    "\n",
    "\n",
    "CH_1 = 1\n",
    "CH_2 = 2\n",
    "CH_COUNT = 2\n",
    "\n",
    "TIME_OFFSET = 0\n",
    "CH_OFFSET = 1\n",
    "CMD_OFFSET = 2\n",
    "CHANNEL_OFFSET = 3\n",
    "PARAM1_OFFSET = 4\n",
    "PARAM2_OFFSET = 5\n",
    "PARAM3_OFFSET = 6\n",
    "SIZE_OF_INPUT_FIELDS = 7\n",
    "\n",
    "WINDOW_SIZE = 256\n",
    "\n",
    "M_CYCLES_PER_SECOND = 4194304.\n",
    "NORMALIZE_TIME_BY = M_CYCLES_PER_SECOND * 3.\n",
    "\n",
    "def norm(val, max_val):\n",
    "    if val > max_val:\n",
    "        return 1.\n",
    "    else:\n",
    "        return ((val / max_val) * 2.) - 1.\n",
    "\n",
    "def unnorm(val, max_val):\n",
    "    return ((val + 1.) / 2.) * max_val\n",
    "\n",
    "def fresh_input(command, channel, time):\n",
    "    newd = np.zeros(shape=SIZE_OF_INPUT_FIELDS, dtype=float)\n",
    "    newd[TIME_OFFSET] = norm(time, NORMALIZE_TIME_BY)\n",
    "\n",
    "    if int(channel) == 1:\n",
    "        newd[CH_OFFSET] = norm(CH_1, CH_COUNT)\n",
    "    elif int(channel) == 2:\n",
    "        newd[CH_OFFSET] = norm(CH_2, CH_COUNT)\n",
    "    else:\n",
    "        raise \"I didn't expect this\"\n",
    "\n",
    "    newd[CMD_OFFSET] = norm(channel, CMD_COUNT)\n",
    "    return newd\n",
    "\n",
    "def nop():\n",
    "    return fresh_input(NOP_CMD_OFFSET, 1, 0)\n",
    "\n",
    "def norm_command_of_parts(command, channel, parts, time):\n",
    "    inp = fresh_input(command, channel, time)\n",
    "    \n",
    "    if command == CMD_DUTYLL:\n",
    "        inp[PARAM1_OFFSET] = norm(float(parts[3]), 2.)\n",
    "        inp[PARAM2_OFFSET] = norm(float(parts[4]), 64.)\n",
    "    elif command == CMD_VOLENVPER:\n",
    "        inp[PARAM1_OFFSET] = float(parts[3]) / 16.\n",
    "        inp[PARAM2_OFFSET] = float(parts[4])\n",
    "        inp[PARAM3_OFFSET] = float(parts[4]) / 7.\n",
    "    elif command == CMD_LSB:\n",
    "        inp[PARAM1_OFFSET] = norm(float(parts[3]), 255.)\n",
    "        inp[PARAM2_OFFSET] = 0.\n",
    "        inp[PARAM3_OFFSET] = 0\n",
    "    elif command == CMD_MSB:\n",
    "        inp[PARAM1_OFFSET] = norm(float(parts[3]), 7.)\n",
    "        inp[PARAM2_OFFSET] = float(bool(parts[4]))\n",
    "        inp[PARAM3_OFFSET] = float(bool(parts[5]))\n",
    "    else:\n",
    "        raise \"this should not happen\"\n",
    "        \n",
    "    return inp\n",
    "\n",
    "def unnorm_feature(data):\n",
    "    def l_unnorm(channel, maxv):\n",
    "        data[channel] = unnorm(data[channel], maxv)\n",
    "    l_unnorm(TIME_OFFSET, NORMALIZE_TIME_BY)\n",
    "    # 4 cycles is the minimum distance between time points\n",
    "    data[TIME_OFFSET] = max(data[TIME_OFFSET], 4)\n",
    "    \n",
    "    l_unnorm(CH_OFFSET, CH_COUNT)\n",
    "    data[CH_OFFSET] = round(data[CH_OFFSET])\n",
    "    \n",
    "    l_unnorm(CMD_OFFSET, CMD_COUNT)\n",
    "    data[CMD_OFFSET] = round(data[CMD_OFFSET])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_training_data(src):\n",
    "    data = []\n",
    "    file = open(src, 'r')\n",
    "    for line in file:\n",
    "        parts = line.split()\n",
    "        if len(parts) > 0 and parts[0] == \"CH\":\n",
    "            #print(parts)\n",
    "            channel = int(parts[1])\n",
    "            command = parts[2]\n",
    "            time = int(parts[-1])\n",
    "            if command == \"DUTYLL\":\n",
    "                new_item = norm_command_of_parts(CMD_DUTYLL, channel, parts, time)\n",
    "            elif command == \"VOLENVPER\":\n",
    "                new_item = norm_command_of_parts(CMD_VOLENVPER, channel, parts, time)\n",
    "            elif command == \"FREQLSB\":\n",
    "                new_item = norm_command_of_parts(CMD_LSB, channel, parts, time)\n",
    "            elif command == \"FREQMSB\":\n",
    "                new_item = norm_command_of_parts(CMD_MSB, channel, parts, time)\n",
    "             # Otherwise unknown   \n",
    "            data.append(new_item)\n",
    "           #print(\"NEXTCMD\", data[-1])\n",
    "    return data\n",
    "\n",
    "@pescador.streamable\n",
    "def samples_from_training_data(src, window_size=WINDOW_SIZE):\n",
    "    sample_data = None\n",
    "\n",
    "    try:\n",
    "        sample_data = load_training_data(src)\n",
    "    except Exception as e:\n",
    "        LOGGER.error('Could not load {}: {}'.format(src, str(e)))\n",
    "        raise StopIteration()\n",
    "\n",
    "    true_window_size = window_size + 1\n",
    "\n",
    "    # Pad small samples with nop\n",
    "    while len(sample_data) < true_window_size:\n",
    "        sample_data.append(nop())\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if len(sample_data) == true_window_size:\n",
    "            sample = sample_data\n",
    "        else:\n",
    "            # Sample a random window from the audio file\n",
    "            start_idx = np.random.randint(0, len(sample_data) - true_window_size)\n",
    "            end_idx = start_idx + true_window_size\n",
    "            sample = sample_data[start_idx:end_idx]\n",
    "\n",
    "        sample_input = sample[0:window_size]\n",
    "        sample_output = sample[window_size:window_size+1]\n",
    "\n",
    "        sample_input = np.array(sample_input).astype(np.float32)\n",
    "        sample_output = np.array(sample_output).astype(np.float32)\n",
    "\n",
    "        yield { 'X':sample_input, 'Y': sample_output }\n",
    "\n",
    "def create_batch_generator(paths, batch_size):\n",
    "    streamers = []\n",
    "    for path in paths:\n",
    "        print(\"Creating a batch generator\")\n",
    "        streamers.append(samples_from_training_data(path))\n",
    "        print(\"Done creating batch generator\")\n",
    "    mux = pescador.ShuffledMux(streamers)\n",
    "    batch_gen = pescador.buffer_stream(mux, batch_size)\n",
    "    return batch_gen\n",
    "\n",
    "def training_files(dirp):\n",
    "    return [\n",
    "      os.path.join(root, fname)\n",
    "      for (root, dir_names, file_names) in os.walk(dirp, followlinks=True)\n",
    "      for fname in file_names\n",
    "    ]\n",
    "\n",
    "def create_data_split(paths, batch_size):\n",
    "    train_gen = create_batch_generator(paths, batch_size)\n",
    "    return train_gen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45bb8c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting training data\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Collected\n"
     ]
    }
   ],
   "source": [
    "print(\"Collecting training data\")\n",
    "train_gen = create_data_split(training_files(\"../..//training_data/\"), 1)\n",
    "print(\"Collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21c61214",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m         decay1\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], command_generator\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 75\u001b[0m seed, command_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m command_generator \u001b[38;5;241m=\u001b[39m CommandNet()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m existing_path \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mcommand_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexisting_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m command_generator \u001b[38;5;241m=\u001b[39m command_generator\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     42\u001b[0m command_optimizer\u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(command_generator\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1463\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;66;03m# copy state_dict so _load_from_state_dict can modify it\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(state_dict, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1463\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m     \u001b[38;5;66;03m# mypy isn't aware that \"_metadata\" exists in state_dict\u001b[39;00m\n\u001b[1;32m   1466\u001b[0m     state_dict\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m metadata  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "DIM = SIZE_OF_INPUT_FIELDS * WINDOW_SIZE\n",
    "\n",
    "class CommandNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CommandNet, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.BatchNorm1d(WINDOW_SIZE),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(1, 1, kernel_size=(SIZE_OF_INPUT_FIELDS, 4)),\n",
    "            nn.Flatten(),\n",
    "            nn.Conv1d(1, 1, kernel_size=SIZE_OF_INPUT_FIELDS),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(994, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(256, SIZE_OF_INPUT_FIELDS),\n",
    "        )\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        output = self.main(sequence)\n",
    "        return output\n",
    "\n",
    "\n",
    "EPOCHS = 2000\n",
    "ROUND_SZ = 20000\n",
    "\n",
    "def train():\n",
    "\n",
    "    existing_path = None\n",
    "    command_generator = CommandNet()\n",
    "    \n",
    "    if existing_path != None:\n",
    "        command_generator.load_state_dict(torch.load(existing_path))\n",
    "        \n",
    "    command_generator = command_generator.to(device)\n",
    "\n",
    "    command_optimizer= optim.Adam(command_generator.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "    command_criterion = nn.MSELoss()\n",
    "    \n",
    "    decay1 = optim.lr_scheduler.ExponentialLR(command_optimizer, gamma=0.999)\n",
    "\n",
    "    for iteration in range(EPOCHS):\n",
    "        print(f\"Round {iteration}\")\n",
    "\n",
    "        for i in range(ROUND_SZ):\n",
    "\n",
    "          command_optimizer.zero_grad()\n",
    "\n",
    "          data = next(train_gen)\n",
    "          data_train_cmd = torch.Tensor(data['X']).to(device)\n",
    "          data_test_cmd = torch.Tensor(data['Y'][0]).to(device)\n",
    "            \n",
    "          prediction_command = command_generator(data_train_cmd)\n",
    "          #print(prediction_command.flatten(), data_test_command.flatten())\n",
    "          command_loss = command_criterion(prediction_command, data_test_cmd)\n",
    "          command_loss.backward()\n",
    "          command_optimizer.step()\n",
    "\n",
    "\n",
    "        print(\"Command batch loss:\", command_loss.item())\n",
    "        print(\"Last data:\", unnorm_feature(data_test_cmd.detach().cpu().numpy()[0]))\n",
    "        print(\"Last prediction:\", unnorm_feature(prediction_command.detach().cpu().numpy()[0]))\n",
    "        torch.save(command_generator.state_dict(), \"./\" + str(int(datetime.now().timestamp())) + \".checkpoint.model\")\n",
    "        print(\"Saved checkpoint\")\n",
    "        \n",
    "        decay1.step()\n",
    "\n",
    "    return data['X'][0], command_generator.eval()\n",
    "\n",
    "seed, command_generator = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = next(train_gen)['X']\n",
    "for i in range(10000):\n",
    "    pred = command_generator(torch.Tensor(seed).to(device))\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    print(\"Pred:\", unnorm_feature(pred[0]))\n",
    "    seed = np.array([np.append(seed[0][1:], pred, axis=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c53c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
