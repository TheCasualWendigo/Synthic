{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec8ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pescador\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a429bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger('gbsd')\n",
    "LOGGER.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b16da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c20fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdbf4a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88c156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD_VOLENVPER = 0\n",
    "CMD_DUTYLL = 1\n",
    "CMD_MSB = 2\n",
    "CMD_LSB = 3\n",
    "CMD_COUNT = 4\n",
    "\n",
    "def onehot_cmd(data):\n",
    "    cmd = data[CMD_OFFSET]\n",
    "    nd = [ 0, 0, 0, 0 ]\n",
    "    nd[int(cmd)] = 1\n",
    "    return nd\n",
    "\n",
    "\n",
    "CH_1 = 1\n",
    "CH_2 = 2\n",
    "CH_COUNT = 2\n",
    "\n",
    "TIME_OFFSET = 0\n",
    "CH_OFFSET = 1\n",
    "CMD_OFFSET = 2\n",
    "CHANNEL_OFFSET = 3\n",
    "PARAM1_OFFSET = 4\n",
    "PARAM2_OFFSET = 5\n",
    "PARAM3_OFFSET = 6\n",
    "SIZE_OF_INPUT_FIELDS = 7\n",
    "\n",
    "WINDOW_SIZE = 256\n",
    "\n",
    "M_CYCLES_PER_SECOND = 4194304.\n",
    "NORMALIZE_TIME_BY = M_CYCLES_PER_SECOND * 3.\n",
    "\n",
    "def norm(val, max_val):\n",
    "    if val > max_val:\n",
    "        return 1.\n",
    "    else:\n",
    "        return ((val / max_val) * 2.) - 1.\n",
    "\n",
    "def unnorm(val, max_val):\n",
    "    return ((val + 1.) / 2.) * max_val\n",
    "\n",
    "def fresh_input(command, channel, time):\n",
    "    newd = np.zeros(shape=SIZE_OF_INPUT_FIELDS, dtype=float)\n",
    "    newd[TIME_OFFSET] = norm(time, NORMALIZE_TIME_BY)\n",
    "\n",
    "    if int(channel) == 1:\n",
    "        newd[CH_OFFSET] = norm(CH_1, CH_COUNT)\n",
    "    elif int(channel) == 2:\n",
    "        newd[CH_OFFSET] = norm(CH_2, CH_COUNT)\n",
    "    else:\n",
    "        raise \"I didn't expect this\"\n",
    "\n",
    "    newd[CMD_OFFSET] = norm(channel, CMD_COUNT)\n",
    "    return newd\n",
    "\n",
    "def nop():\n",
    "    return fresh_input(NOP_CMD_OFFSET, 1, 0)\n",
    "\n",
    "def norm_command_of_parts(command, channel, parts, time):\n",
    "    inp = fresh_input(command, channel, time)\n",
    "    \n",
    "    if command == CMD_DUTYLL:\n",
    "        inp[PARAM1_OFFSET] = norm(float(parts[3]), 2.)\n",
    "        inp[PARAM2_OFFSET] = norm(float(parts[4]), 64.)\n",
    "    elif command == CMD_VOLENVPER:\n",
    "        inp[PARAM1_OFFSET] = float(parts[3]) / 16.\n",
    "        inp[PARAM2_OFFSET] = float(parts[4])\n",
    "        inp[PARAM3_OFFSET] = float(parts[4]) / 7.\n",
    "    elif command == CMD_LSB:\n",
    "        inp[PARAM1_OFFSET] = norm(float(parts[3]), 255.)\n",
    "        inp[PARAM2_OFFSET] = 0.\n",
    "        inp[PARAM3_OFFSET] = 0\n",
    "    elif command == CMD_MSB:\n",
    "        inp[PARAM1_OFFSET] = norm(float(parts[3]), 7.)\n",
    "        inp[PARAM2_OFFSET] = float(bool(parts[4]))\n",
    "        inp[PARAM3_OFFSET] = float(bool(parts[5]))\n",
    "    else:\n",
    "        raise \"this should not happen\"\n",
    "        \n",
    "    return inp\n",
    "\n",
    "def unnorm_feature(data):\n",
    "    def l_unnorm(channel, maxv):\n",
    "        data[channel] = unnorm(data[channel], maxv)\n",
    "    l_unnorm(TIME_OFFSET, NORMALIZE_TIME_BY)\n",
    "    # 4 cycles is the minimum distance between time points\n",
    "    data[TIME_OFFSET] = max(data[TIME_OFFSET], 4)\n",
    "    \n",
    "    l_unnorm(CH_OFFSET, CH_COUNT)\n",
    "    data[CH_OFFSET] = round(data[CH_OFFSET])\n",
    "    \n",
    "    l_unnorm(CMD_OFFSET, CMD_COUNT)\n",
    "    data[CMD_OFFSET] = round(data[CMD_OFFSET])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_training_data(src):\n",
    "    data = []\n",
    "    file = open(src, 'r')\n",
    "    for line in file:\n",
    "        parts = line.split()\n",
    "        if len(parts) > 0 and parts[0] == \"CH\":\n",
    "            #print(parts)\n",
    "            channel = int(parts[1])\n",
    "            command = parts[2]\n",
    "            time = int(parts[-1])\n",
    "            if command == \"DUTYLL\":\n",
    "                new_item = norm_command_of_parts(CMD_DUTYLL, channel, parts, time)\n",
    "            elif command == \"VOLENVPER\":\n",
    "                new_item = norm_command_of_parts(CMD_VOLENVPER, channel, parts, time)\n",
    "            elif command == \"FREQLSB\":\n",
    "                new_item = norm_command_of_parts(CMD_LSB, channel, parts, time)\n",
    "            elif command == \"FREQMSB\":\n",
    "                new_item = norm_command_of_parts(CMD_MSB, channel, parts, time)\n",
    "             # Otherwise unknown   \n",
    "            data.append(new_item)\n",
    "           #print(\"NEXTCMD\", data[-1])\n",
    "    return data\n",
    "\n",
    "@pescador.streamable\n",
    "def samples_from_training_data(src, window_size=WINDOW_SIZE):\n",
    "    sample_data = None\n",
    "\n",
    "    try:\n",
    "        sample_data = load_training_data(src)\n",
    "    except Exception as e:\n",
    "        LOGGER.error('Could not load {}: {}'.format(src, str(e)))\n",
    "        raise StopIteration()\n",
    "\n",
    "    true_window_size = window_size + 1\n",
    "\n",
    "    # Pad small samples with nop\n",
    "    while len(sample_data) < true_window_size:\n",
    "        sample_data.append(nop())\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if len(sample_data) == true_window_size:\n",
    "            sample = sample_data\n",
    "        else:\n",
    "            # Sample a random window from the audio file\n",
    "            start_idx = np.random.randint(0, len(sample_data) - true_window_size)\n",
    "            end_idx = start_idx + true_window_size\n",
    "            sample = sample_data[start_idx:end_idx]\n",
    "\n",
    "        sample_input = sample[0:window_size]\n",
    "        sample_output = sample[window_size:window_size+1]\n",
    "\n",
    "        sample_input = np.array(sample_input).astype(np.float32)\n",
    "        sample_output = np.array(sample_output).astype(np.float32)\n",
    "\n",
    "        yield { 'X':sample_input, 'Y': sample_output }\n",
    "\n",
    "def create_batch_generator(paths, batch_size):\n",
    "    streamers = []\n",
    "    for path in paths:\n",
    "        print(\"Creating a batch generator\")\n",
    "        streamers.append(samples_from_training_data(path))\n",
    "        print(\"Done creating batch generator\")\n",
    "    mux = pescador.ShuffledMux(streamers)\n",
    "    batch_gen = pescador.buffer_stream(mux, batch_size)\n",
    "    return batch_gen\n",
    "\n",
    "def training_files(dirp):\n",
    "    return [\n",
    "      os.path.join(root, fname)\n",
    "      for (root, dir_names, file_names) in os.walk(dirp, followlinks=True)\n",
    "      for fname in file_names\n",
    "    ]\n",
    "\n",
    "def create_data_split(paths, batch_size):\n",
    "    train_gen = create_batch_generator(paths, batch_size)\n",
    "    return train_gen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45bb8c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting training data\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Collected\n"
     ]
    }
   ],
   "source": [
    "print(\"Collecting training data\")\n",
    "train_gen = create_data_split(training_files(\"../..//training_data/\"), 1)\n",
    "print(\"Collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c61214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "Command batch loss: 0.0068533169105648994\n",
      "Last data: [28.125       1.          1.          0.          0.42857143  1.\n",
      "  1.        ]\n",
      "Last prediction: [31367.25           1.             1.             0.00192593\n",
      "     0.53640014     0.8551078      0.90162975]\n",
      "Saved checkpoint\n",
      "Round 1\n",
      "Command batch loss: 0.18036523461341858\n",
      "Last data: [592.125       1.          1.          0.         -0.9607843   0.\n",
      "   0.       ]\n",
      "Last prediction: [4.         1.         1.         0.00188623 0.03750512 0.2702093\n",
      " 0.21645547]\n",
      "Saved checkpoint\n",
      "Round 2\n",
      "Command batch loss: 0.2467152625322342\n",
      "Last data: [71332.125     1.        1.        0.        1.       -1.        0.   ]\n",
      "Last prediction: [103711.875           1.              1.              0.00143044\n",
      "      0.6609226       0.14032806      0.39172837]\n",
      "Saved checkpoint\n",
      "Round 3\n",
      "Command batch loss: 0.020517567172646523\n",
      "Last data: [28.125  1.     1.     0.     1.     1.     1.   ]\n",
      "Last prediction: [14871.75           1.             1.             0.00291834\n",
      "     0.8983921      0.8665417      0.86761165]\n",
      "Saved checkpoint\n",
      "Round 4\n",
      "Command batch loss: 0.1197362095117569\n",
      "Last data: [55.875       1.          1.          0.          0.71428573  1.\n",
      "  1.        ]\n",
      "Last prediction: [50265.             1.             1.            -0.00216631\n",
      "     0.5737137      0.52028483     0.43784288]\n",
      "Saved checkpoint\n",
      "Round 5\n",
      "Command batch loss: 0.25634074211120605\n",
      "Last data: [120.           1.           1.           0.           0.71428573\n",
      "   1.           1.        ]\n",
      "Last prediction: [38734.125          1.             1.             0.00055476\n",
      "     0.346334       0.18059587     0.09088881]\n",
      "Saved checkpoint\n",
      "Round 6\n",
      "Command batch loss: 0.05054395645856857\n",
      "Last data: [36.  2.  2.  0.  1.  1.  1.]\n",
      "Last prediction: [23420.25           2.             2.             0.00386965\n",
      "     0.71143967     0.72158223     0.68244416]\n",
      "Saved checkpoint\n",
      "Round 7\n",
      "Command batch loss: 0.19617663323879242\n",
      "Last data: [55.875       2.          2.          0.          0.71428573  1.\n",
      "  1.        ]\n",
      "Last prediction: [139546.88            2.              2.             -0.00128627\n",
      "      0.05931655      0.39395183      0.30311194]\n",
      "Saved checkpoint\n",
      "Round 8\n",
      "Command batch loss: 0.011804236099123955\n",
      "Last data: [235.875       1.          1.          0.          0.1764706   0.\n",
      "   0.       ]\n",
      "Last prediction: [162157.88            1.              1.              0.00211176\n",
      "      0.31570652     -0.06539916      0.01785153]\n",
      "Saved checkpoint\n",
      "Round 9\n",
      "Command batch loss: 0.0025536753237247467\n",
      "Last data: [36.  2.  2.  0.  1.  1.  1.]\n",
      "Last prediction: [20324.25           2.             2.            -0.00118518\n",
      "     0.9378401      0.97332704     1.0220292 ]\n",
      "Saved checkpoint\n",
      "Round 10\n",
      "Command batch loss: 0.19220656156539917\n",
      "Last data: [2716.125        1.           1.           0.          -0.9607843\n",
      "    0.           0.       ]\n",
      "Last prediction: [ 4.          1.          1.         -0.00116048  0.074099    0.3507291\n",
      "  0.2896371 ]\n",
      "Saved checkpoint\n",
      "Round 11\n",
      "Command batch loss: 0.013604958541691303\n",
      "Last data: [55.875       1.          1.          0.          0.71428573  1.\n",
      "  1.        ]\n",
      "Last prediction: [ 4.          1.          1.         -0.0000123   0.5882796   0.8757652\n",
      "  0.77770364]\n",
      "Saved checkpoint\n",
      "Round 12\n",
      "Command batch loss: 0.008661650121212006\n",
      "Last data: [66732.     1.     1.     0.     1.    -1.     0.]\n",
      "Last prediction: [254803.5             1.              1.              0.00241745\n",
      "      0.79286695     -0.93605363     -0.02577333]\n",
      "Saved checkpoint\n",
      "Round 13\n",
      "Command batch loss: 0.28406429290771484\n",
      "Last data: [67324.125     2.        2.        0.        1.       -1.        0.   ]\n",
      "Last prediction: [93772.875          2.             2.            -0.00017764\n",
      "     0.40029812     0.22658163     0.24849047]\n",
      "Saved checkpoint\n",
      "Round 14\n",
      "Command batch loss: 0.0038160961121320724\n",
      "Last data: [28.125  2.     2.     0.     1.     1.     1.   ]\n",
      "Last prediction: [41454.75           2.             2.            -0.00019607\n",
      "     1.1013925      1.0401014      1.0761094 ]\n",
      "Saved checkpoint\n",
      "Round 15\n",
      "Command batch loss: 0.000606190413236618\n",
      "Last data: [36.          1.          1.          0.          0.71428573  1.\n",
      "  1.        ]\n",
      "Last prediction: [4.         1.         1.         0.00106841 0.7686285  0.97651774\n",
      " 0.9858203 ]\n",
      "Saved checkpoint\n",
      "Round 16\n",
      "Command batch loss: 0.010323971509933472\n",
      "Last data: [28.125       2.          2.          0.          0.42857143  1.\n",
      "  1.        ]\n",
      "Last prediction: [ 4.          2.          2.         -0.00140725  0.6924704   0.9993592\n",
      "  1.0210754 ]\n",
      "Saved checkpoint\n",
      "Round 17\n",
      "Command batch loss: 0.00462412741035223\n",
      "Last data: [336300.              1.              1.              0.\n",
      "     -0.49803922      0.              0.        ]\n",
      "Last prediction: [235367.25            1.              1.              0.00011124\n",
      "     -0.64452124      0.00003374      0.0187113 ]\n",
      "Saved checkpoint\n",
      "Round 18\n",
      "Command batch loss: 0.3920922577381134\n",
      "Last data: [69631.875     1.        1.        0.        0.375     0.        0.   ]\n",
      "Last prediction: [ 4.          2.          2.         -0.00019795  0.9300119   0.97001845\n",
      "  1.0168812 ]\n",
      "Saved checkpoint\n",
      "Round 19\n",
      "Command batch loss: 0.029405254870653152\n",
      "Last data: [24.          2.          2.          0.         -0.03529412  0.\n",
      "  0.        ]\n",
      "Last prediction: [ 4.          2.          2.          0.00007803  0.4172689  -0.02645125\n",
      " -0.00816989]\n",
      "Saved checkpoint\n",
      "Round 20\n",
      "Command batch loss: 0.036730363965034485\n",
      "Last data: [115.875        2.           2.           0.           0.71428573\n",
      "   1.           1.        ]\n",
      "Last prediction: [ 4.          2.          2.         -0.00062971  0.2883151   0.8671286\n",
      "  0.89310235]\n",
      "Saved checkpoint\n",
      "Round 21\n",
      "Command batch loss: 0.10260503739118576\n",
      "Last data: [60.          1.          1.          0.          0.75        1.\n",
      "  0.14285715]\n",
      "Last prediction: [4.         2.         2.         0.00040375 0.33644843 1.0122943\n",
      " 0.1415343 ]\n",
      "Saved checkpoint\n",
      "Round 22\n",
      "Command batch loss: 0.059097398072481155\n",
      "Last data: [2032.125         1.            1.            0.           -0.16078432\n",
      "    0.            0.        ]\n",
      "Last prediction: [64081.5            1.             1.             0.00014874\n",
      "    -0.19237965    -0.638461       0.01758877]\n",
      "Saved checkpoint\n",
      "Round 23\n",
      "Command batch loss: 0.043907854706048965\n",
      "Last data: [28.125       2.          2.          0.          0.14285715  1.\n",
      "  1.        ]\n",
      "Last prediction: [4.         2.         2.         0.00007647 0.69656336 0.9929352\n",
      " 0.99107975]\n",
      "Saved checkpoint\n",
      "Round 24\n",
      "Command batch loss: 0.06771466135978699\n",
      "Last data: [232.125   2.      2.      0.      1.      1.      1.   ]\n",
      "Last prediction: [40728.75           2.             2.            -0.00002671\n",
      "     0.5360967      0.77884287     0.600509  ]\n",
      "Saved checkpoint\n",
      "Round 25\n",
      "Command batch loss: 0.0008736972813494503\n",
      "Last data: [19.875  1.     1.     0.     0.375  0.     0.   ]\n",
      "Last prediction: [55372.875          1.             1.            -0.00086347\n",
      "     0.42572537    -0.04519159    -0.01479403]\n",
      "Saved checkpoint\n",
      "Round 26\n",
      "Command batch loss: 0.004523551091551781\n",
      "Last data: [19.875  1.     1.     0.     1.     0.     0.   ]\n",
      "Last prediction: [182344.12            1.              1.             -0.00092118\n",
      "      0.8605281      -0.05993799      0.00398658]\n",
      "Saved checkpoint\n",
      "Round 27\n",
      "Command batch loss: 0.00984702818095684\n",
      "Last data: [19.875       2.          2.          0.         -0.64705884  0.\n",
      "  0.        ]\n",
      "Last prediction: [ 4.          2.          2.         -0.00001443 -0.40131584 -0.0264862\n",
      "  0.00906056]\n",
      "Saved checkpoint\n",
      "Round 28\n",
      "Command batch loss: 0.04960102215409279\n",
      "Last data: [203388.      1.      1.      0.      1.     -1.      0.]\n",
      "Last prediction: [246421.5             1.              1.             -0.00132142\n",
      "      0.51819396     -0.6849136      -0.01190593]\n",
      "Saved checkpoint\n",
      "Round 29\n",
      "Command batch loss: 0.02370504103600979\n",
      "Last data: [592.125       2.          2.          0.          0.8039216   0.\n",
      "   0.       ]\n",
      "Last prediction: [4.         2.         2.         0.00011773 0.4079669  0.02546712\n",
      " 0.00151799]\n",
      "Saved checkpoint\n",
      "Round 30\n",
      "Command batch loss: 0.0008030579192563891\n",
      "Last data: [135816.             2.             2.             0.\n",
      "     -0.7411765      0.             0.       ]\n",
      "Last prediction: [34411.5            2.             2.             0.00106631\n",
      "    -0.6722961      0.00161896    -0.02038416]\n",
      "Saved checkpoint\n",
      "Round 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command batch loss: 0.0015040540602058172\n",
      "Last data: [16.125  1.     1.     0.     0.375  0.     0.   ]\n",
      "Last prediction: [6724.875         1.            1.            0.00103602    0.4737506\n",
      "    0.00010899   -0.02355104]\n",
      "Saved checkpoint\n",
      "Round 32\n",
      "Command batch loss: 0.0005366562982089818\n",
      "Last data: [31.875       1.          1.          0.          0.42857143  1.\n",
      "  1.        ]\n",
      "Last prediction: [ 4.          1.          1.         -0.00036701  0.3788336   1.0166888\n",
      "  1.0313729 ]\n",
      "Saved checkpoint\n",
      "Round 33\n",
      "Command batch loss: 0.0008273495477624238\n",
      "Last data: [19.875  2.     2.     0.     1.    -1.     0.   ]\n",
      "Last prediction: [ 4.          2.          2.          0.00127314  0.93674344 -1.0037365\n",
      " -0.01203388]\n",
      "Saved checkpoint\n",
      "Round 34\n",
      "Command batch loss: 0.0014718422899022698\n",
      "Last data: [31.875  1.     1.     0.    -1.     0.     0.   ]\n",
      "Last prediction: [211717.5             1.              1.             -0.00052255\n",
      "     -0.9593871       0.01670722     -0.02870818]\n",
      "Saved checkpoint\n",
      "Round 35\n",
      "Command batch loss: 0.008401033468544483\n",
      "Last data: [52.125       1.          1.          0.          0.71428573  1.\n",
      "  1.        ]\n",
      "Last prediction: [17115.375          1.             1.             0.00123549\n",
      "     0.7890419      0.89210767     0.85436773]\n",
      "Saved checkpoint\n",
      "Round 36\n",
      "Command batch loss: 0.01669400930404663\n",
      "Last data: [753300.          1.          1.          0.          0.3125      0.\n",
      "      0.    ]\n",
      "Last prediction: [343232.62            1.              1.             -0.00120873\n",
      "      0.52341455     -0.25953844     -0.02626836]\n",
      "Saved checkpoint\n",
      "Round 37\n",
      "Command batch loss: 0.0670153945684433\n",
      "Last data: [232.125        1.           1.           0.           0.71428573\n",
      "   1.           1.        ]\n",
      "Last prediction: [65033.625          1.             1.             0.00020353\n",
      "     0.44080776     0.6870661      0.50667906]\n",
      "Saved checkpoint\n",
      "Round 38\n",
      "Command batch loss: 0.0016612649196758866\n",
      "Last data: [19.875  2.     2.     0.     1.    -1.     0.   ]\n",
      "Last prediction: [134236.88            2.              2.             -0.00035096\n",
      "      0.93299377     -0.9391003       0.0070821 ]\n",
      "Saved checkpoint\n",
      "Round 39\n",
      "Command batch loss: 0.028193429112434387\n",
      "Last data: [592.125        1.           1.           0.           0.92941177\n",
      "   0.           0.        ]\n",
      "Last prediction: [ 4.          1.          1.         -0.00079714  0.48613092  0.02277491\n",
      "  0.01533996]\n",
      "Saved checkpoint\n",
      "Round 40\n",
      "Command batch loss: 0.07776591181755066\n",
      "Last data: [264.        2.        2.        0.        0.       -0.78125   0.     ]\n",
      "Last prediction: [134678.25            2.              2.              0.00001429\n",
      "     -0.14594428     -0.05864604     -0.02110411]\n",
      "Saved checkpoint\n",
      "Round 41\n",
      "Command batch loss: 0.0017026502173393965\n",
      "Last data: [48.  2.  2.  0.  1.  1.  1.]\n",
      "Last prediction: [4.         2.         2.         0.00055947 0.91321474 1.0224197\n",
      " 1.0032775 ]\n",
      "Saved checkpoint\n",
      "Round 42\n",
      "Command batch loss: 0.0072861528024077415\n",
      "Last data: [16.125  2.     2.     0.     1.     1.     1.   ]\n",
      "Last prediction: [72073.125          2.             2.            -0.00004536\n",
      "     0.88555413     0.88856554     0.85821056]\n",
      "Saved checkpoint\n",
      "Round 43\n",
      "Command batch loss: 0.008234215900301933\n",
      "Last data: [3132.       1.       1.       0.       0.625    0.       0.   ]\n",
      "Last prediction: [64267.5            1.             1.            -0.00062962\n",
      "     0.38642275    -0.01060528     0.00434181]\n",
      "Saved checkpoint\n",
      "Round 44\n",
      "Command batch loss: 0.002110888948664069\n",
      "Last data: [28.125  2.     2.     0.     1.     1.     1.   ]\n",
      "Last prediction: [4.         2.         2.         0.00002169 0.93498397 0.92834663\n",
      " 0.9296813 ]\n",
      "Saved checkpoint\n",
      "Round 45\n",
      "Command batch loss: 0.011085138656198978\n",
      "Last data: [64.125  1.     1.     0.     0.625  0.     0.   ]\n",
      "Last prediction: [25849.5            1.             1.            -0.0003333\n",
      "     0.36516154     0.09782441    -0.01096919]\n",
      "Saved checkpoint\n",
      "Round 46\n",
      "Command batch loss: 0.008028744719922543\n",
      "Last data: [288.    2.    2.    0.    0.5   0.    0. ]\n",
      "Last prediction: [4.         2.         2.         0.00019208 0.49337348 0.00847083\n",
      " 0.02152538]\n",
      "Saved checkpoint\n",
      "Round 47\n",
      "Command batch loss: 0.02746148407459259\n",
      "Last data: [100.125        1.           1.           0.           0.625\n",
      "   1.           0.14285715]\n",
      "Last prediction: [24291.75           1.             1.            -0.00023936\n",
      "     0.48371705     0.7093634      0.3979391 ]\n",
      "Saved checkpoint\n",
      "Round 48\n",
      "Command batch loss: 0.0006654884782619774\n",
      "Last data: [55.875       1.          1.          0.          0.71428573  1.\n",
      "  1.        ]\n",
      "Last prediction: [10779.75           1.             1.             0.00015793\n",
      "     0.6480434      1.0003082      1.0161278 ]\n",
      "Saved checkpoint\n",
      "Round 49\n",
      "Command batch loss: 0.018536044284701347\n",
      "Last data: [65736.             2.             2.             0.\n",
      "     0.33333334     0.             0.        ]\n",
      "Last prediction: [ 4.          2.          2.          0.00656151 -0.02332468 -0.01678044\n",
      "  0.03983331]\n",
      "Saved checkpoint\n",
      "Round 50\n",
      "Command batch loss: 0.0008779818890616298\n",
      "Last data: [64.125       1.          1.          0.          0.79607844  0.\n",
      "  0.        ]\n",
      "Last prediction: [11448.             1.             1.             0.00053049\n",
      "     0.73722124     0.04063174     0.02062746]\n",
      "Saved checkpoint\n",
      "Round 51\n",
      "Command batch loss: 0.015464020892977715\n",
      "Last data: [3672.     1.     1.     0.     0.5    0.     0. ]\n",
      "Last prediction: [ 4.          1.          1.          0.00101599  0.822429   -0.05780897\n",
      " -0.02391938]\n",
      "Saved checkpoint\n",
      "Round 52\n",
      "Command batch loss: 0.029613053426146507\n",
      "Last data: [66312.        2.        2.        0.        0.875     0.        0.   ]\n",
      "Last prediction: [9486.75          2.            2.           -0.00032042    0.55441165\n",
      "    0.06219558    0.03431879]\n",
      "Saved checkpoint\n",
      "Round 53\n",
      "Command batch loss: 0.04841701686382294\n",
      "Last data: [31.875  1.     1.     0.     0.    -1.     0.   ]\n",
      "Last prediction: [44701.875          1.             1.            -0.00009573\n",
      "    -0.17864263    -0.52738       -0.00378263]\n",
      "Saved checkpoint\n",
      "Round 54\n",
      "Command batch loss: 0.0008025377755984664\n",
      "Last data: [55.875       2.          2.          0.          0.39607844  0.\n",
      "  0.        ]\n",
      "Last prediction: [4856.25          2.            2.            0.00149376    0.4674995\n",
      "    0.00381547    0.02100092]\n",
      "Saved checkpoint\n",
      "Round 55\n",
      "Command batch loss: 0.0038155890069901943\n",
      "Last data: [68404.125          1.             1.             0.\n",
      "     0.42745098     0.             0.        ]\n",
      "Last prediction: [32116.5            1.             1.             0.00070192\n",
      "     0.5393163      0.09261879     0.06664666]\n",
      "Saved checkpoint\n",
      "Round 56\n",
      "Command batch loss: 0.23119406402111053\n",
      "Last data: [316.125     2.        2.        0.        1.        0.96875   0.     ]\n",
      "Last prediction: [4.         2.         2.         0.00005898 0.13112849 0.17166987\n",
      " 0.16050929]\n",
      "Saved checkpoint\n",
      "Round 57\n",
      "Command batch loss: 0.0002842648536898196\n",
      "Last data: [28.125       2.          2.          0.          0.71428573  1.\n",
      "  1.        ]\n",
      "Last prediction: [4.        2.        2.        0.0002795 0.7572202 1.0105553 1.0002261]\n",
      "Saved checkpoint\n",
      "Round 58\n",
      "Command batch loss: 0.0006161080673336983\n",
      "Last data: [28.125       2.          2.          0.          0.71428573  1.\n",
      "  1.        ]\n",
      "Last prediction: [ 4.          2.          2.         -0.00027284  0.7698805   1.0223916\n",
      "  1.0247366 ]\n",
      "Saved checkpoint\n",
      "Round 59\n",
      "Command batch loss: 0.006155680399388075\n",
      "Last data: [66520.125          1.             1.             0.\n",
      "    -0.23921569     0.             0.        ]\n",
      "Last prediction: [65016.             1.             1.             0.00010239\n",
      "    -0.04461227    -0.07012837    -0.00077573]\n",
      "Saved checkpoint\n",
      "Round 60\n",
      "Command batch loss: 0.00055487803183496\n",
      "Last data: [135216.             2.             2.             0.\n",
      "     -0.7647059      0.             0.       ]\n",
      "Last prediction: [17118.75           2.             2.             0.00012737\n",
      "    -0.81377953    -0.01693219     0.02822458]\n",
      "Saved checkpoint\n",
      "Round 61\n",
      "Command batch loss: 0.0024638078175485134\n",
      "Last data: [66643.875         1.            1.            0.           -0.8666667\n",
      "     0.            0.       ]\n",
      "Last prediction: [116854.125           1.              1.              0.00142131\n",
      "     -0.7361091      -0.00305273      0.00144726]\n",
      "Saved checkpoint\n",
      "Round 62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command batch loss: 0.03200821578502655\n",
      "Last data: [65563.875          2.             2.             0.\n",
      "     0.94509804     0.             0.        ]\n",
      "Last prediction: [209608.12            2.              2.              0.00035333\n",
      "      0.4771077      -0.03556806     -0.00562216]\n",
      "Saved checkpoint\n",
      "Round 63\n",
      "Command batch loss: 0.0012860088609158993\n",
      "Last data: [52.125  2.     2.     0.     1.     1.     1.   ]\n",
      "Last prediction: [ 4.          2.          2.         -0.00150876  0.91586727  0.9700697\n",
      "  0.98236555]\n",
      "Saved checkpoint\n",
      "Round 64\n",
      "Command batch loss: 6.361850682878867e-05\n",
      "Last data: [19.875  2.     2.     0.     0.75   0.     0.   ]\n",
      "Last prediction: [22573.125          2.             2.            -0.00082632\n",
      "     0.7424825     -0.01239703    -0.00826009]\n",
      "Saved checkpoint\n",
      "Round 65\n",
      "Command batch loss: 0.0003282022080384195\n",
      "Last data: [24.          2.          2.          0.         -0.03529412  0.\n",
      "  0.        ]\n",
      "Last prediction: [46885.875          2.             2.            -0.00067522\n",
      "    -0.00812517    -0.00328982     0.03639263]\n",
      "Saved checkpoint\n",
      "Round 66\n",
      "Command batch loss: 0.03741723299026489\n",
      "Last data: [55.875       1.          1.          0.          0.71428573  1.\n",
      "  1.        ]\n",
      "Last prediction: [99761.25           1.             1.             0.00106077\n",
      "     0.542967       0.8070347      0.6279001 ]\n",
      "Saved checkpoint\n",
      "Round 67\n",
      "Command batch loss: 0.0001054312233463861\n",
      "Last data: [31.875  1.     1.     0.    -1.     0.     0.   ]\n",
      "Last prediction: [ 4.          1.          1.         -0.00023084 -1.000744   -0.00952651\n",
      " -0.00755229]\n",
      "Saved checkpoint\n",
      "Round 68\n",
      "Command batch loss: 0.01719667948782444\n",
      "Last data: [67720.125          1.             1.             0.\n",
      "     0.21568628     0.             0.        ]\n",
      "Last prediction: [297711.38            1.              1.             -0.00006398\n",
      "      0.559727        0.00528446      0.0032593 ]\n",
      "Saved checkpoint\n",
      "Round 69\n",
      "Command batch loss: 0.015105430036783218\n",
      "Last data: [427.875        1.           1.           0.           0.70980394\n",
      "   0.           0.        ]\n",
      "Last prediction: [26730.             1.             1.            -0.00037462\n",
      "     0.38710406     0.01166765     0.03799548]\n",
      "Saved checkpoint\n",
      "Round 70\n",
      "Command batch loss: 0.021530935540795326\n",
      "Last data: [15600.             2.             2.             0.\n",
      "    -0.64705884     0.             0.        ]\n",
      "Last prediction: [129057.75            2.              2.              0.00070533\n",
      "     -0.28357255      0.00618288      0.02351384]\n",
      "Saved checkpoint\n",
      "Round 71\n",
      "Command batch loss: 0.02998911589384079\n",
      "Last data: [346200.          1.          1.          0.          0.6875      0.\n",
      "      0.    ]\n",
      "Last prediction: [283767.              1.              1.              0.00007097\n",
      "      0.2334384      -0.06006109     -0.00006702]\n",
      "Saved checkpoint\n",
      "Round 72\n",
      "Command batch loss: 0.008470918983221054\n",
      "Last data: [324.   2.   2.   0.   1.  -1.   0.]\n",
      "Last prediction: [106263.75            2.              2.             -0.00175904\n",
      "      0.7748751      -0.9322185       0.03437554]\n",
      "Saved checkpoint\n",
      "Round 73\n",
      "Command batch loss: 0.19499018788337708\n",
      "Last data: [65724.             2.             2.             0.\n",
      "    -0.31764707     0.             0.        ]\n",
      "Last prediction: [66891.75           1.             1.             0.00043412\n",
      "     0.26609063     0.00584821     0.0370757 ]\n",
      "Saved checkpoint\n",
      "Round 74\n",
      "Command batch loss: 0.0016729396302253008\n",
      "Last data: [55.875       2.          2.          0.         -0.27058825  0.\n",
      "  0.        ]\n",
      "Last prediction: [ 4.          2.          2.          0.00031492 -0.3734694  -0.00530375\n",
      " -0.01510119]\n",
      "Saved checkpoint\n",
      "Round 75\n",
      "Command batch loss: 0.1044420376420021\n",
      "Last data: [68412.             1.             1.             0.\n",
      "    -0.01960784     0.             0.        ]\n",
      "Last prediction: [ 4.          2.          2.          0.00013717 -0.06676833  0.05528094\n",
      "  0.02829945]\n",
      "Saved checkpoint\n",
      "Round 76\n",
      "Command batch loss: 0.07354655116796494\n",
      "Last data: [67360.125      1.         1.         0.         0.9375     0.\n",
      "     0.    ]\n",
      "Last prediction: [133229.25            1.              1.             -0.00021812\n",
      "      0.24735223      0.06873453      0.00766216]\n",
      "Saved checkpoint\n",
      "Round 77\n",
      "Command batch loss: 0.019061867147684097\n",
      "Last data: [277579.88            2.              2.              0.\n",
      "     -0.75686276      0.              0.        ]\n",
      "Last prediction: [102078.              2.              2.              0.00109193\n",
      "     -0.3991656      -0.02720645      0.00173388]\n",
      "Saved checkpoint\n",
      "Round 78\n",
      "Command batch loss: 0.02996618114411831\n",
      "Last data: [68440.125          1.             1.             0.\n",
      "     0.42745098     0.             0.        ]\n",
      "Last prediction: [32458.5            1.             1.             0.00003037\n",
      "    -0.02933042     0.02269802     0.00965161]\n",
      "Saved checkpoint\n",
      "Round 79\n",
      "Command batch loss: 0.14823636412620544\n",
      "Last data: [444.           2.           2.           0.           0.85882354\n",
      "   0.           0.        ]\n",
      "Last prediction: [17757.             2.             2.            -0.00168897\n",
      "     0.91624916     0.7365826      0.7011839 ]\n",
      "Saved checkpoint\n",
      "Round 80\n",
      "Command batch loss: 0.021442348137497902\n",
      "Last data: [24.  1.  1.  0.  1. -1.  0.]\n",
      "Last prediction: [55046.25           1.             1.            -0.00354231\n",
      "     0.8648983     -0.8753111      0.03191223]\n",
      "Saved checkpoint\n",
      "Round 81\n",
      "Command batch loss: 0.009042550809681416\n",
      "Last data: [48.          1.          1.          0.          0.71428573  1.\n",
      "  1.        ]\n",
      "Last prediction: [14502.75           1.             1.             0.00198757\n",
      "     0.46459955     0.9950547      0.9702097 ]\n",
      "Saved checkpoint\n",
      "Round 82\n",
      "Command batch loss: 0.009154949337244034\n",
      "Last data: [28.125  2.     2.     0.     1.     1.     1.   ]\n",
      "Last prediction: [57169.125          2.             2.            -0.00005929\n",
      "     0.94822675     0.915502       0.9459386 ]\n",
      "Saved checkpoint\n",
      "Round 83\n",
      "Command batch loss: 0.010850491002202034\n",
      "Last data: [68292.            1.            1.            0.           -0.5372549\n",
      "     0.            0.       ]\n",
      "Last prediction: [43089.375          1.             1.             0.00178109\n",
      "    -0.4882014      0.06391299     0.0417649 ]\n",
      "Saved checkpoint\n",
      "Round 84\n",
      "Command batch loss: 7.463138172170147e-05\n",
      "Last data: [202459.88            2.              2.              0.\n",
      "     -0.73333335      0.              0.        ]\n",
      "Last prediction: [175482.75            2.              2.              0.00133534\n",
      "     -0.7140125      -0.00436933      0.00392557]\n",
      "Saved checkpoint\n",
      "Round 85\n",
      "Command batch loss: 0.004379469435662031\n",
      "Last data: [28.125       2.          2.          0.          0.71428573  1.\n",
      "  1.        ]\n",
      "Last prediction: [77127.             2.             2.             0.00007214\n",
      "     0.6683321      0.9587881      0.9617951 ]\n",
      "Saved checkpoint\n",
      "Round 86\n",
      "Command batch loss: 0.07005287706851959\n",
      "Last data: [69076.125     2.        2.        0.        0.75      0.        0.   ]\n",
      "Last prediction: [95037.             1.             1.             0.00007344\n",
      "     0.43928295     0.11266474     0.11706089]\n",
      "Saved checkpoint\n",
      "Round 87\n",
      "Command batch loss: 0.0012325267307460308\n",
      "Last data: [28.125       2.          2.          0.          0.42857143  1.\n",
      "  1.        ]\n",
      "Last prediction: [11707.875          2.             2.             0.00057606\n",
      "     0.50471264     0.9579499      0.9680805 ]\n",
      "Saved checkpoint\n",
      "Round 88\n",
      "Command batch loss: 0.009723879396915436\n",
      "Last data: [19.875  2.     2.     0.     1.    -1.     0.   ]\n",
      "Last prediction: [ 4.          2.          2.          0.00007411  0.9285629  -0.9187066\n",
      "  0.01231864]\n",
      "Saved checkpoint\n",
      "Round 89\n",
      "Command batch loss: 0.0007142300019040704\n",
      "Last data: [28.125       1.          1.          0.          0.42857143  1.\n",
      "  1.        ]\n",
      "Last prediction: [12291.             1.             1.            -0.00026613\n",
      "     0.36984283     0.9730482      0.98107064]\n",
      "Saved checkpoint\n",
      "Round 90\n",
      "Command batch loss: 0.0003810877678915858\n",
      "Last data: [76.125  2.     2.     0.     1.     1.     1.   ]\n",
      "Last prediction: [4.         2.         2.         0.00087056 1.0250033  0.99621505\n",
      " 0.983162  ]\n",
      "Saved checkpoint\n",
      "Round 91\n",
      "Command batch loss: 0.0005393336759880185\n",
      "Last data: [76.125  1.     1.     0.     1.     1.     1.   ]\n",
      "Last prediction: [4.         1.         1.         0.00128863 0.94260937 0.99227536\n",
      " 0.9819581 ]\n",
      "Saved checkpoint\n",
      "Round 92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command batch loss: 0.002504279837012291\n",
      "Last data: [16.125  1.     1.     0.     1.     1.     1.   ]\n",
      "Last prediction: [1005.75          1.            1.           -0.00012393    0.962223\n",
      "    1.0639693     1.038677  ]\n",
      "Saved checkpoint\n",
      "Round 93\n",
      "Command batch loss: 0.0012468647910282016\n",
      "Last data: [288.      2.      2.      0.      0.625   0.      0.   ]\n",
      "Last prediction: [27698.25           2.             2.            -0.00006187\n",
      "     0.53810686     0.01410449     0.00482623]\n",
      "Saved checkpoint\n",
      "Round 94\n",
      "Command batch loss: 0.036874882876873016\n",
      "Last data: [66348.        2.        2.        0.        0.875     0.        0.   ]\n",
      "Last prediction: [4.         2.         2.         0.00224188 0.52678055 0.04812048\n",
      " 0.06789383]\n",
      "Saved checkpoint\n",
      "Round 95\n",
      "Command batch loss: 0.027544241398572922\n",
      "Last data: [592.125        2.           2.           0.           0.01960784\n",
      "   0.           0.        ]\n",
      "Last prediction: [ 4.          2.          2.          0.00002268  0.45676756  0.00811609\n",
      " -0.00602232]\n",
      "Saved checkpoint\n",
      "Round 96\n",
      "Command batch loss: 0.005811198614537716\n",
      "Last data: [100.125        2.           2.           0.          -0.64705884\n",
      "   0.           0.        ]\n",
      "Last prediction: [54783.75           2.             2.            -0.00057615\n",
      "    -0.4460538      0.0091126      0.00994123]\n",
      "Saved checkpoint\n",
      "Round 97\n",
      "Command batch loss: 0.007090657018125057\n",
      "Last data: [67111.875         1.            1.            0.            0.7176471\n",
      "     0.            0.       ]\n",
      "Last prediction: [73002.             1.             1.             0.00029484\n",
      "     0.5418734      0.097876       0.08073574]\n",
      "Saved checkpoint\n",
      "Round 98\n",
      "Command batch loss: 0.003811279311776161\n",
      "Last data: [232.125   1.      1.      0.      1.      1.      1.   ]\n",
      "Last prediction: [16275.             1.             1.            -0.00242153\n",
      "     0.9072631      1.0062051      0.8754261 ]\n",
      "Saved checkpoint\n",
      "Round 99\n",
      "Command batch loss: 0.28095853328704834\n",
      "Last data: [232.125        2.           2.           0.           0.71428573\n",
      "   1.           1.        ]\n",
      "Last prediction: [80536.5            1.             1.            -0.00044695\n",
      "     0.24333358     0.12966311     0.19493888]\n",
      "Saved checkpoint\n",
      "Round 100\n",
      "Command batch loss: 0.003693224163725972\n",
      "Last data: [66264.             1.             1.             0.\n",
      "     0.09803922     0.             0.        ]\n",
      "Last prediction: [110464.5             1.              1.              0.00085665\n",
      "     -0.06225248      0.00100784      0.00981359]\n",
      "Saved checkpoint\n",
      "Round 101\n",
      "Command batch loss: 0.004279131069779396\n",
      "Last data: [55.875       2.          2.          0.          0.09019608  0.\n",
      "  0.        ]\n",
      "Last prediction: [33958.875          2.             2.            -0.00025184\n",
      "     0.26098275     0.02170008     0.01516075]\n",
      "Saved checkpoint\n",
      "Round 102\n",
      "Command batch loss: 0.1307322382926941\n",
      "Last data: [19.875  1.     1.     0.     1.     0.     0.   ]\n",
      "Last prediction: [118309.5             2.              2.              0.00037195\n",
      "      0.52977836      0.04194876      0.01668216]\n",
      "Saved checkpoint\n",
      "Round 103\n",
      "Command batch loss: 0.00721856951713562\n",
      "Last data: [28.125       2.          2.          0.          0.71428573  1.\n",
      "  1.        ]\n",
      "Last prediction: [29523.75           2.             2.            -0.00143381\n",
      "     0.489847       1.0067375      1.0079781 ]\n",
      "Saved checkpoint\n",
      "Round 104\n",
      "Command batch loss: 0.010491258464753628\n",
      "Last data: [1356.        2.        2.        0.        0.0625    0.        0.    ]\n",
      "Last prediction: [91767.375          2.             2.             0.00039648\n",
      "    -0.03617438    -0.2505129     -0.01774705]\n",
      "Saved checkpoint\n",
      "Round 105\n",
      "Command batch loss: 0.003645691554993391\n",
      "Last data: [68976.             1.             1.             0.\n",
      "     0.34901962     0.             0.        ]\n",
      "Last prediction: [7231.875         1.            1.           -0.00087717    0.5071241\n",
      "    0.01864233    0.00719414]\n",
      "Saved checkpoint\n",
      "Round 106\n",
      "Command batch loss: 0.00047798416926525533\n",
      "Last data: [19.875       2.          2.          0.          0.71428573  1.\n",
      "  1.        ]\n",
      "Last prediction: [9711.75          2.            2.            0.00048867    0.73892534\n",
      "    0.998279      0.9945238 ]\n",
      "Saved checkpoint\n",
      "Round 107\n",
      "Command batch loss: 0.010179463773965836\n",
      "Last data: [24.          1.          1.          0.         -0.05098039  0.\n",
      "  0.        ]\n",
      "Last prediction: [4.         1.         1.         0.00064818 0.21132764 0.04892695\n",
      " 0.00139075]\n",
      "Saved checkpoint\n",
      "Round 108\n",
      "Command batch loss: 0.009593956172466278\n",
      "Last data: [76.125  2.     2.     0.     1.     1.     1.   ]\n",
      "Last prediction: [ 4.          2.          2.         -0.00018484  0.82658356  0.9427143\n",
      "  0.93026954]\n",
      "Saved checkpoint\n",
      "Round 109\n",
      "Command batch loss: 0.0010112837189808488\n",
      "Last data: [55.875  2.     2.     0.     1.     1.     1.   ]\n",
      "Last prediction: [8522.625         2.            2.           -0.00010099    0.9756376\n",
      "    1.0035928     1.0155246 ]\n",
      "Saved checkpoint\n",
      "Round 110\n",
      "Command batch loss: 0.00010369045048719272\n",
      "Last data: [64075.875      2.         2.         0.         0.5625     0.\n",
      "     0.    ]\n",
      "Last prediction: [47855.25           2.             2.            -0.00090944\n",
      "     0.57534635    -0.01525866    -0.00072886]\n",
      "Saved checkpoint\n",
      "Round 111\n",
      "Command batch loss: 0.00029341154731810093\n",
      "Last data: [28.125       1.          1.          0.          0.42857143  1.\n",
      "  1.        ]\n",
      "Last prediction: [6403.875         1.            1.           -0.00339075    0.43770278\n",
      "    0.96705353    0.974631  ]\n",
      "Saved checkpoint\n",
      "Round 112\n",
      "Command batch loss: 0.02136130817234516\n",
      "Last data: [138588.      2.      2.      0.      1.     -1.      0.]\n",
      "Last prediction: [202641.75            2.              2.             -0.00111336\n",
      "      0.7868046      -0.6820837      -0.00565513]\n",
      "Saved checkpoint\n",
      "Round 113\n",
      "Command batch loss: 0.001467962865717709\n",
      "Last data: [24.          2.          2.          0.          0.39607844  0.\n",
      "  0.        ]\n",
      "Last prediction: [40452.375          2.             2.            -0.00016133\n",
      "     0.49224904     0.00444208    -0.00926189]\n",
      "Saved checkpoint\n",
      "Round 114\n",
      "Command batch loss: 0.00019394316768739372\n",
      "Last data: [28.125  1.     1.     0.     1.     1.     1.   ]\n",
      "Last prediction: [ 4.          1.          1.         -0.0007203   1.0202981   0.99794364\n",
      "  0.99756545]\n",
      "Saved checkpoint\n",
      "Round 115\n",
      "Command batch loss: 0.004015455488115549\n",
      "Last data: [264.        2.        2.        0.        1.       -0.71875   0.     ]\n",
      "Last prediction: [189267.              2.              2.              0.00090699\n",
      "      1.023978       -0.88020855      0.01815961]\n",
      "Saved checkpoint\n",
      "Round 116\n",
      "Command batch loss: 0.006416763179004192\n",
      "Last data: [1927.875        1.           1.           0.           0.3882353\n",
      "    0.           0.       ]\n",
      "Last prediction: [48716.625          1.             1.            -0.00112655\n",
      "     0.17735967    -0.01734822    -0.00815633]\n",
      "Saved checkpoint\n",
      "Round 117\n"
     ]
    }
   ],
   "source": [
    "DIM = SIZE_OF_INPUT_FIELDS * WINDOW_SIZE\n",
    "\n",
    "class CommandNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CommandNet, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.BatchNorm1d(WINDOW_SIZE),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(1, 1, kernel_size=(SIZE_OF_INPUT_FIELDS, 4)),\n",
    "            nn.Flatten(),\n",
    "            nn.Conv1d(1, 1, kernel_size=SIZE_OF_INPUT_FIELDS),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(994, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(256, SIZE_OF_INPUT_FIELDS),\n",
    "        )\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        output = self.main(sequence)\n",
    "        return output\n",
    "\n",
    "\n",
    "EPOCHS = 2000\n",
    "ROUND_SZ = 20000\n",
    "\n",
    "def train():\n",
    "\n",
    "    existing_path = None\n",
    "    command_generator = CommandNet()\n",
    "    \n",
    "    if existing_path != None:\n",
    "        command_generator.load_state_dict(torch.load(existing_path))\n",
    "        \n",
    "    command_generator = command_generator.to(device)\n",
    "\n",
    "    command_optimizer= optim.Adam(command_generator.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "    command_criterion = nn.MSELoss()\n",
    "    \n",
    "    decay1 = optim.lr_scheduler.ExponentialLR(command_optimizer, gamma=0.999)\n",
    "\n",
    "    for iteration in range(EPOCHS):\n",
    "        print(f\"Round {iteration}\")\n",
    "\n",
    "        for i in range(ROUND_SZ):\n",
    "\n",
    "          command_optimizer.zero_grad()\n",
    "\n",
    "          data = next(train_gen)\n",
    "          data_train_cmd = torch.Tensor(data['X']).to(device)\n",
    "          data_test_cmd = torch.Tensor(data['Y'][0]).to(device)\n",
    "            \n",
    "          prediction_command = command_generator(data_train_cmd)\n",
    "          #print(prediction_command.flatten(), data_test_command.flatten())\n",
    "          command_loss = command_criterion(prediction_command, data_test_cmd)\n",
    "          command_loss.backward()\n",
    "          command_optimizer.step()\n",
    "\n",
    "\n",
    "        print(\"Command batch loss:\", command_loss.item())\n",
    "        print(\"Last data:\", unnorm_feature(data_test_cmd.detach().cpu().numpy()[0]))\n",
    "        print(\"Last prediction:\", unnorm_feature(prediction_command.detach().cpu().numpy()[0]))\n",
    "        torch.save(command_generator.state_dict(), \"./\" + str(int(datetime.now().timestamp())) + \".checkpoint.model\")\n",
    "        print(\"Saved checkpoint\")\n",
    "        \n",
    "        decay1.step()\n",
    "\n",
    "    return data['X'][0], command_generator.eval()\n",
    "\n",
    "seed, command_generator = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = next(train_gen)['X']\n",
    "for i in range(10000):\n",
    "    pred = command_generator(torch.Tensor(seed).to(device))\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    print(\"Pred:\", unnorm_feature(pred[0]))\n",
    "    seed = np.array([np.append(seed[0][1:], pred, axis=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c53c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
