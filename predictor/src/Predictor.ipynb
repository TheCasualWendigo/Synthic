{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec8ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pescador\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a429bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger('gbsd')\n",
    "LOGGER.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b16da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c20fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdbf4a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88c156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD_VOLENVPER = 0\n",
    "CMD_DUTYLL = 1\n",
    "CMD_MSB = 2\n",
    "CMD_LSB = 3\n",
    "CMD_COUNT = 4\n",
    "\n",
    "def onehot_cmd(data):\n",
    "    cmd = data[CMD_OFFSET]\n",
    "    nd = [ 0, 0, 0, 0 ]\n",
    "    nd[int(cmd)] = 1\n",
    "    return nd\n",
    "\n",
    "\n",
    "CH_1 = 0\n",
    "CH_2 = 1\n",
    "CH_COUNT = 2\n",
    "\n",
    "TIME_OFFSET = 0\n",
    "CH_OFFSET = 1\n",
    "CMD_OFFSET = 2\n",
    "PARAM1_OFFSET = 3\n",
    "PARAM2_OFFSET = 4\n",
    "PARAM3_OFFSET = 5\n",
    "SIZE_OF_INPUT_FIELDS = 6\n",
    "\n",
    "WINDOW_SIZE = 256\n",
    "\n",
    "M_CYCLES_PER_SECOND = 4194304.\n",
    "NORMALIZE_TIME_BY = M_CYCLES_PER_SECOND * 3.\n",
    "\n",
    "def norm(val, max_val):\n",
    "    if val > max_val:\n",
    "        return 1.\n",
    "    else:\n",
    "        return ((val / max_val) * 2.) - 1.\n",
    "\n",
    "def unnorm(val, max_val):\n",
    "    return ((val + 1.) / 2.) * max_val\n",
    "\n",
    "def fresh_input(command, channel, time):\n",
    "    newd = np.zeros(shape=SIZE_OF_INPUT_FIELDS, dtype=float)\n",
    "    newd[TIME_OFFSET] = norm(time, NORMALIZE_TIME_BY)\n",
    "\n",
    "    if int(channel) == 1:\n",
    "        newd[CH_OFFSET] = norm(CH_1, CH_COUNT)\n",
    "    elif int(channel) == 2:\n",
    "        newd[CH_OFFSET] = norm(CH_2, CH_COUNT)\n",
    "    else:\n",
    "        raise \"I didn't expect this\"\n",
    "\n",
    "    newd[CMD_OFFSET] = norm(command, CMD_COUNT)\n",
    "    return newd\n",
    "\n",
    "def nop():\n",
    "    return fresh_input(NOP_CMD_OFFSET, 1, 0)\n",
    "\n",
    "def norm_command_of_parts(command, channel, parts, time):\n",
    "    inp = fresh_input(command, channel, time)\n",
    "    \n",
    "    if command == CMD_DUTYLL:\n",
    "        inp[PARAM1_OFFSET] = norm(float(parts[3]), 2.)\n",
    "        inp[PARAM2_OFFSET] = norm(float(parts[4]), 64.)\n",
    "    elif command == CMD_VOLENVPER:\n",
    "        inp[PARAM1_OFFSET] = float(parts[3]) / 16.\n",
    "        inp[PARAM2_OFFSET] = float(parts[4])\n",
    "        inp[PARAM3_OFFSET] = float(parts[4]) / 7.\n",
    "    elif command == CMD_LSB:\n",
    "        inp[PARAM1_OFFSET] = norm(float(parts[3]), 255.)\n",
    "        inp[PARAM2_OFFSET] = 0.\n",
    "        inp[PARAM3_OFFSET] = 0\n",
    "    elif command == CMD_MSB:\n",
    "        inp[PARAM1_OFFSET] = norm(float(parts[3]), 7.)\n",
    "        inp[PARAM2_OFFSET] = float(bool(parts[4]))\n",
    "        inp[PARAM3_OFFSET] = float(bool(parts[5]))\n",
    "    else:\n",
    "        raise \"this should not happen\"\n",
    "        \n",
    "    return inp\n",
    "\n",
    "def unnorm_feature(data):\n",
    "    \n",
    "    data = data.copy()\n",
    "    \n",
    "    # Unnormalize a channel given a specific max value\n",
    "    def l_unnorm(channel, maxv):\n",
    "        data[channel] = unnorm(data[channel], maxv)\n",
    "    \n",
    "    # Round and box a channel to a min and max value\n",
    "    def l_round(channel, minv, maxv):\n",
    "        data[channel] = round(min(max(data[channel], minv), maxv))\n",
    "    \n",
    "    l_unnorm(TIME_OFFSET, NORMALIZE_TIME_BY)\n",
    "    # 4 cycles is the minimum distance between time points\n",
    "    data[TIME_OFFSET] = round(max(data[TIME_OFFSET], 4))\n",
    "    \n",
    "    l_unnorm(CH_OFFSET, CH_COUNT)\n",
    "    data[CH_OFFSET] = round(data[CH_OFFSET])\n",
    "    \n",
    "    l_unnorm(CMD_OFFSET, CMD_COUNT)\n",
    "    data[CMD_OFFSET] = round(data[CMD_OFFSET])\n",
    "    \n",
    "    command = data[CMD_OFFSET]\n",
    "    \n",
    "    if command == CMD_DUTYLL:\n",
    "        l_unnorm(PARAM1_OFFSET, 2)\n",
    "        l_round(PARAM1_OFFSET, 0, 2)\n",
    "        \n",
    "        l_unnorm(PARAM2_OFFSET, 64)\n",
    "        l_round(PARAM2_OFFSET, 0, 64)\n",
    "        \n",
    "        data[PARAM3_OFFSET] = 0.\n",
    "    elif command == CMD_VOLENVPER:\n",
    "        \n",
    "        l_unnorm(PARAM1_OFFSET, 16)\n",
    "        l_round(PARAM1_OFFSET, 0, 16)\n",
    "        \n",
    "        data[PARAM2_OFFSET] = round(data[PARAM2_OFFSET])\n",
    "        \n",
    "        l_unnorm(PARAM3_OFFSET, 7)\n",
    "        l_round(PARAM3_OFFSET, 0, 7)\n",
    "    elif command == CMD_LSB:\n",
    "        \n",
    "        l_unnorm(PARAM1_OFFSET, 255.)\n",
    "        l_round(PARAM1_OFFSET, 0., 255.)\n",
    "        \n",
    "        data[PARAM2_OFFSET] = 0.\n",
    "        \n",
    "        data[PARAM3_OFFSET] = 0.\n",
    "    elif command == CMD_MSB:\n",
    "        l_unnorm(PARAM1_OFFSET, 7.)\n",
    "        l_round(PARAM1_OFFSET, 0., 7.)\n",
    "        \n",
    "        l_round(PARAM2_OFFSET, 0., 1.)\n",
    "        l_round(PARAM3_OFFSET, 0., 1.)\n",
    "    else:\n",
    "        print(\"Bad prediction\")\n",
    "        return None\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_training_data(src):\n",
    "    data = []\n",
    "    file = open(src, 'r')\n",
    "    for line in file:\n",
    "        parts = line.split()\n",
    "        if len(parts) > 0 and parts[0] == \"CH\":\n",
    "            #print(parts)\n",
    "            channel = int(parts[1])\n",
    "            command = parts[2]\n",
    "            time = int(parts[-1])\n",
    "            if command == \"DUTYLL\":\n",
    "                new_item = norm_command_of_parts(CMD_DUTYLL, channel, parts, time)\n",
    "            elif command == \"VOLENVPER\":\n",
    "                new_item = norm_command_of_parts(CMD_VOLENVPER, channel, parts, time)\n",
    "            elif command == \"FREQLSB\":\n",
    "                new_item = norm_command_of_parts(CMD_LSB, channel, parts, time)\n",
    "            elif command == \"FREQMSB\":\n",
    "                new_item = norm_command_of_parts(CMD_MSB, channel, parts, time)\n",
    "            else:\n",
    "                print(\"Unknown\", command)\n",
    "             # Otherwise unknown   \n",
    "            data.append(new_item)\n",
    "           #print(\"NEXTCMD\", data[-1])\n",
    "    return data\n",
    "\n",
    "@pescador.streamable\n",
    "def samples_from_training_data(src, window_size=WINDOW_SIZE):\n",
    "    sample_data = None\n",
    "\n",
    "    try:\n",
    "        sample_data = load_training_data(src)\n",
    "    except Exception as e:\n",
    "        LOGGER.error('Could not load {}: {}'.format(src, str(e)))\n",
    "        raise StopIteration()\n",
    "\n",
    "    true_window_size = window_size + 1\n",
    "\n",
    "    # Pad small samples with nop\n",
    "    while len(sample_data) < true_window_size:\n",
    "        sample_data.append(nop())\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if len(sample_data) == true_window_size:\n",
    "            sample = sample_data\n",
    "        else:\n",
    "            # Sample a random window from the audio file\n",
    "            start_idx = np.random.randint(0, len(sample_data) - true_window_size)\n",
    "            end_idx = start_idx + true_window_size\n",
    "            sample = sample_data[start_idx:end_idx]\n",
    "\n",
    "        sample_input = sample[0:window_size]\n",
    "        sample_output = sample[window_size:window_size+1]\n",
    "\n",
    "        sample_input = np.array(sample_input).astype(np.float32)\n",
    "        sample_output = np.array(sample_output).astype(np.float32)\n",
    "\n",
    "        yield { 'X':sample_input, 'Y': sample_output }\n",
    "\n",
    "def create_batch_generator(paths, batch_size):\n",
    "    streamers = []\n",
    "    for path in paths:\n",
    "        print(\"Creating a batch generator\")\n",
    "        streamers.append(samples_from_training_data(path))\n",
    "        print(\"Done creating batch generator\")\n",
    "    mux = pescador.ShuffledMux(streamers)\n",
    "    batch_gen = pescador.buffer_stream(mux, batch_size)\n",
    "    return batch_gen\n",
    "\n",
    "def training_files(dirp):\n",
    "    return [\n",
    "      os.path.join(root, fname)\n",
    "      for (root, dir_names, file_names) in os.walk(dirp, followlinks=True)\n",
    "      for fname in file_names\n",
    "    ]\n",
    "\n",
    "def create_data_split(paths, batch_size):\n",
    "    train_gen = create_batch_generator(paths, batch_size)\n",
    "    return train_gen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45bb8c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting training data\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Collected\n"
     ]
    }
   ],
   "source": [
    "print(\"Collecting training data\")\n",
    "train_gen = create_data_split(training_files(\"../..//training_data/\"), 1)\n",
    "print(\"Collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c61214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "Command batch loss: 0.4730592668056488\n",
      "Last data: [68528.     0.     3.    91.     0.     0.]\n",
      "Last prediction: [329976.      0.      1.      2.      0.      0.]\n",
      "Saved checkpoint\n",
      "Round 1\n",
      "Command batch loss: 0.00546613335609436\n",
      "Last data: [28.  1.  2.  6.  1.  1.]\n",
      "Last prediction: [4. 1. 2. 6. 1. 1.]\n",
      "Saved checkpoint\n",
      "Round 2\n",
      "Command batch loss: 0.02501573972404003\n",
      "Last data: [48.  1.  2.  7.  1.  1.]\n",
      "Last prediction: [4. 1. 2. 6. 1. 1.]\n",
      "Saved checkpoint\n",
      "Round 3\n",
      "Command batch loss: 0.008427998051047325\n",
      "Last data: [20.  1.  0. 14.  0.  4.]\n",
      "Last prediction: [ 4.  1.  0. 14.  0.  3.]\n",
      "Saved checkpoint\n",
      "Round 4\n",
      "Command batch loss: 0.06782934069633484\n",
      "Last data: [56.  0.  2.  6.  1.  1.]\n",
      "Last prediction: [80168.     0.     1.     2.    56.     0.]\n",
      "Saved checkpoint\n",
      "Round 5\n",
      "Command batch loss: 0.014548173174262047\n",
      "Last data: [48.  0.  2.  7.  1.  1.]\n",
      "Last prediction: [4. 0. 2. 6. 1. 1.]\n",
      "Saved checkpoint\n",
      "Round 6\n",
      "Command batch loss: 0.10550158470869064\n",
      "Last data: [541120.      1.      0.      9.      0.      4.]\n",
      "Last prediction: [154924.      0.      1.      1.     25.      0.]\n",
      "Saved checkpoint\n",
      "Round 7\n",
      "Command batch loss: 0.16968464851379395\n",
      "Last data: [64.  0.  0.  8.  1.  4.]\n",
      "Last prediction: [ 4.  0.  0. 11.  0.  4.]\n",
      "Saved checkpoint\n",
      "Round 8\n",
      "Command batch loss: 0.035545144230127335\n",
      "Last data: [ 56.   1.   3. 237.   0.   0.]\n",
      "Last prediction: [  4.   1.   3. 182.   0.   0.]\n",
      "Saved checkpoint\n",
      "Round 9\n",
      "Command batch loss: 0.06616690754890442\n",
      "Last data: [68236.     0.     3.    17.     0.     0.]\n",
      "Last prediction: [41368.     0.     3.    82.     0.     0.]\n",
      "Saved checkpoint\n",
      "Round 10\n",
      "Command batch loss: 0.03676093369722366\n",
      "Last data: [16.  1.  2.  5.  1.  1.]\n",
      "Last prediction: [20769.     1.     2.     7.     1.     1.]\n",
      "Saved checkpoint\n",
      "Round 11\n",
      "Command batch loss: 0.10583244264125824\n",
      "Last data: [64752.     1.     3.   247.     0.     0.]\n",
      "Last prediction: [231051.      1.      2.      5.      0.      0.]\n",
      "Saved checkpoint\n",
      "Round 12\n",
      "Command batch loss: 0.0008259487221948802\n",
      "Last data: [56.  1.  3. 22.  0.  0.]\n",
      "Last prediction: [10480.     1.     3.    24.     0.     0.]\n",
      "Saved checkpoint\n",
      "Round 13\n",
      "Command batch loss: 0.014189213514328003\n",
      "Last data: [336304.      0.      3.     64.      0.      0.]\n",
      "Last prediction: [81149.     0.     3.    72.     0.     0.]\n",
      "Saved checkpoint\n",
      "Round 14\n"
     ]
    }
   ],
   "source": [
    "DIM = SIZE_OF_INPUT_FIELDS * WINDOW_SIZE\n",
    "\n",
    "class CommandNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CommandNet, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.BatchNorm1d(WINDOW_SIZE),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(1, 1, kernel_size=(SIZE_OF_INPUT_FIELDS, 4)),\n",
    "            nn.Flatten(),\n",
    "            nn.Conv1d(1, 1, kernel_size=SIZE_OF_INPUT_FIELDS),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(748, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(256, SIZE_OF_INPUT_FIELDS),\n",
    "        )\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        output = self.main(sequence)\n",
    "        return output\n",
    "\n",
    "\n",
    "EPOCHS = 10000000\n",
    "ROUND_SZ = 20000\n",
    "\n",
    "def train():\n",
    "\n",
    "    existing_path = None\n",
    "    command_generator = CommandNet()\n",
    "    \n",
    "    if existing_path != None:\n",
    "        command_generator.load_state_dict(torch.load(existing_path))\n",
    "        \n",
    "    command_generator = command_generator.to(device)\n",
    "\n",
    "    command_optimizer= optim.Adam(command_generator.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "    command_criterion = nn.MSELoss()\n",
    "    \n",
    "    decay1 = optim.lr_scheduler.ExponentialLR(command_optimizer, gamma=0.999)\n",
    "\n",
    "    for iteration in range(EPOCHS):\n",
    "        print(f\"Round {iteration}\")\n",
    "\n",
    "        for i in range(ROUND_SZ):\n",
    "\n",
    "          command_optimizer.zero_grad()\n",
    "\n",
    "          data = next(train_gen)\n",
    "          data_train_cmd = torch.Tensor(data['X']).to(device)\n",
    "          data_test_cmd = torch.Tensor(data['Y'][0]).to(device)\n",
    "            \n",
    "          prediction_command = command_generator(data_train_cmd)\n",
    "          #print(prediction_command.flatten(), data_test_command.flatten())\n",
    "          command_loss = command_criterion(prediction_command, data_test_cmd)\n",
    "          command_loss.backward()\n",
    "          command_optimizer.step()\n",
    "\n",
    "\n",
    "        print(\"Command batch loss:\", command_loss.item())\n",
    "        print(\"Last data:\", unnorm_feature(data_test_cmd.detach().cpu().numpy()[0]))\n",
    "        print(\"Last prediction:\", unnorm_feature(prediction_command.detach().cpu().numpy()[0]))\n",
    "        torch.save(command_generator.state_dict(), \"./\" + str(int(datetime.now().timestamp())) + \".checkpoint.model\")\n",
    "        print(\"Saved checkpoint\")\n",
    "        \n",
    "        decay1.step()\n",
    "\n",
    "    return data['X'][0], command_generator.eval()\n",
    "\n",
    "seed, command_generator = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = next(train_gen)['X']\n",
    "\n",
    "for i in seed[0]:\n",
    "    print(unnorm_feature(i))\n",
    "\n",
    "for i in range(10000):\n",
    "    pred = command_generator(torch.Tensor(seed).to(device))\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    seed = np.array([np.append(seed[0][1:], pred, axis=0)])\n",
    "    pred = unnorm_feature(pred[0])\n",
    "    if pred[CMD_OFFSET] != 1 and pred[CMD_OFFSET] != 2:\n",
    "        print(\"REEE: Something else\", pred[0][CMD_OFFSET])\n",
    "    print(\"Pred:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c53c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
