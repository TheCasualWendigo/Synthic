{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59503796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pescador\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a856308",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger('gbsd')\n",
    "LOGGER.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3ff3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f5c3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4469c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD_VOLENVPER = 0\n",
    "CMD_DUTYLL = 1\n",
    "CMD_MSB = 2\n",
    "CMD_LSB = 3\n",
    "CMD_COUNT = 4\n",
    "\n",
    "def onehot_cmd(data):\n",
    "    cmd = data[CMD_OFFSET]\n",
    "    nd = [ 0, 0, 0, 0 ]\n",
    "    nd[int(cmd)] = 1\n",
    "    return nd\n",
    "\n",
    "TIME_OFFSET = 0\n",
    "CH_1_OFFSET = 1\n",
    "CH_2_OFFSET = 2\n",
    "CMD_OFFSET = 3\n",
    "CHANNEL_OFFSET = 4\n",
    "DUTY_OFFSET = 5\n",
    "LENGTH_OFFSET = 6\n",
    "VOL_OFFSET = 7\n",
    "ADD_MODE_OFFSET = 8\n",
    "PERIOD_OFFSET = 9\n",
    "FREQLSB_OFFSET = 10\n",
    "FREQMSB_OFFSET = 11\n",
    "LENGTH_ENABLE_OFFSET = 12\n",
    "TRIGGER_OFFSET = 13\n",
    "NUM_INP = 14\n",
    "\n",
    "WINDOW_SIZE = 1024\n",
    "\n",
    "NORMALIZE_TIME_BY = float(4194304 * 3) # 1 second is 4194304 cycles so this is 10s\n",
    "\n",
    "def norm(val, max_val):\n",
    "    return ((val / max_val) * 2.) - 1.\n",
    "\n",
    "def unnorm(val, max_val):\n",
    "    return ((val + 1.) / 2.) * max_val\n",
    "\n",
    "def fresh_input(command, channel, time):\n",
    "    newd = np.zeros(shape=NUM_INP, dtype=float)\n",
    "    newd[TIME_OFFSET] = norm(time, NORMALIZE_TIME_BY)\n",
    "    #print(channel)\n",
    "    if int(channel) == 1:\n",
    "        newd[CH_1_OFFSET] = 1.\n",
    "    elif int(channel) == 2:\n",
    "        newd[CH_2_OFFSET] = 1.\n",
    "    else:\n",
    "        raise \"I didn't expect this\"\n",
    "    newd[CMD_OFFSET] = channel\n",
    "    return newd\n",
    "\n",
    "def nop():\n",
    "    return fresh_input(NOP_CMD_OFFSET, 1, 0)\n",
    "\n",
    "def duty_ll(channel, parts, time):\n",
    "    inp = fresh_input(CMD_DUTYLL, channel, time)\n",
    "    inp[DUTY_OFFSET] = norm(float(parts[3]), 2.)\n",
    "    inp[LENGTH_OFFSET] = norm(float(parts[4]), 64.)\n",
    "    return inp\n",
    "\n",
    "def volenvper(channel, parts, time):\n",
    "    inp = fresh_input(CMD_VOLENVPER, channel, time)\n",
    "    inp[VOL_OFFSET] = float(parts[3]) / 16.\n",
    "    inp[ADD_MODE_OFFSET] = float(parts[4])\n",
    "    inp[PERIOD_OFFSET] = float(parts[4]) / 7.\n",
    "    return inp\n",
    "\n",
    "def freqlsb(channel, parts, time):\n",
    "    inp = fresh_input(CMD_LSB, channel, time)\n",
    "    inp[FREQLSB_OFFSET] = norm(float(parts[3]), 255.)\n",
    "    return inp\n",
    "\n",
    "def freqmsb(channel, parts, time):\n",
    "    inp = fresh_input(CMD_MSB, channel, time)\n",
    "    inp[FREQMSB_OFFSET] = norm(float(parts[3]), 7.)\n",
    "    inp[LENGTH_ENABLE_OFFSET] = float(bool(parts[4]))\n",
    "    inp[TRIGGER_OFFSET] = float(bool(parts[5]))\n",
    "    return inp\n",
    "\n",
    "def load_training_data(src):\n",
    "    data = []\n",
    "    file = open(src, 'r')\n",
    "    for line in file:\n",
    "        parts = line.split()\n",
    "        if len(parts) > 0 and parts[0] == \"CH\":\n",
    "           #print(parts)\n",
    "           channel = int(parts[1])\n",
    "           command = parts[2]\n",
    "           time = int(parts[-1])\n",
    "           if command == \"DUTYLL\":\n",
    "               data.append(duty_ll(channel, parts, time))\n",
    "           if command == \"VOLENVPER\":\n",
    "               data.append(volenvper(channel, parts, time))\n",
    "           if command == \"FREQLSB\":\n",
    "               data.append(freqlsb(channel, parts, time))\n",
    "           if command == \"FREQMSB\":\n",
    "               data.append(freqmsb(channel, parts, time))\n",
    "           #print(\"NEXTCMD\", data[-1])\n",
    "    return data\n",
    "\n",
    "@pescador.streamable\n",
    "def samples_from_training_data(src, window_size=WINDOW_SIZE):\n",
    "    sample_data = None\n",
    "\n",
    "    try:\n",
    "        sample_data = load_training_data(src)\n",
    "    except Exception as e:\n",
    "        LOGGER.error('Could not load {}: {}'.format(src, str(e)))\n",
    "        raise StopIteration()\n",
    "\n",
    "    true_window_size = window_size + 1\n",
    "\n",
    "    # Pad small samples with nop\n",
    "    while len(sample_data) < true_window_size:\n",
    "        sample_data.append(nop())\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if len(sample_data) == true_window_size:\n",
    "            sample = sample_data\n",
    "        else:\n",
    "            # Sample a random window from the audio file\n",
    "            start_idx = np.random.randint(0, len(sample_data) - true_window_size)\n",
    "            end_idx = start_idx + true_window_size\n",
    "            sample = sample_data[start_idx:end_idx]\n",
    "\n",
    "        sample_input = sample[0:window_size]\n",
    "        sample_output = sample[window_size:window_size+1]\n",
    "\n",
    "        sample_input = np.array(sample_input).astype(np.float32)\n",
    "        sample_output = np.array(sample_output).astype(np.float32)\n",
    "\n",
    "        yield { 'X':sample_input, 'Y': sample_output }\n",
    "\n",
    "def create_batch_generator(paths, batch_size):\n",
    "    streamers = []\n",
    "    for path in paths:\n",
    "        print(\"Creating a batch generator\")\n",
    "        streamers.append(samples_from_training_data(path))\n",
    "        print(\"Done creating batch generator\")\n",
    "    mux = pescador.ShuffledMux(streamers)\n",
    "    batch_gen = pescador.buffer_stream(mux, batch_size)\n",
    "    return batch_gen\n",
    "\n",
    "def training_files(dirp):\n",
    "    return [\n",
    "      os.path.join(root, fname)\n",
    "      for (root, dir_names, file_names) in os.walk(dirp, followlinks=True)\n",
    "      for fname in file_names\n",
    "    ]\n",
    "\n",
    "def create_data_split(paths, batch_size):\n",
    "    train_gen = create_batch_generator(paths, batch_size)\n",
    "    return train_gen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35cb1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "ROUND_SZ = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f235e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EVENTS_PER_ROUND = WINDOW_SIZE\n",
    "DIM = NUM_INP * NUM_EVENTS_PER_ROUND\n",
    "\n",
    "class TimeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeNet, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(WINDOW_SIZE, 64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        output = self.main(noise)\n",
    "        return output\n",
    "\n",
    "class CommandNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CommandNet, self).__init__()\n",
    "\n",
    "        self.cmd_embedding = nn.Embedding(CMD_COUNT, 1)\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Conv1d(1, 1, kernel_size=NUM_INP),\n",
    "            nn.Conv1d(1, 1, kernel_size=NUM_INP),\n",
    "            nn.Conv1d(1, 1, kernel_size=NUM_INP),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(985, 128),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(128, CMD_COUNT),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        sequence = [self.cmd_embedding(sequence[:,i + CMD_OFFSET].type(torch.IntTensor).to(device)) for i in range(0, DIM, NUM_INP)]\n",
    "        sequence = torch.cat(sequence, 1)\n",
    "        output = self.main(sequence)\n",
    "        return output\n",
    "\n",
    "class ChannelNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ChannelNet, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Flatt\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(DIM, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(512, 2),\n",
    "\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        output = self.main(noise)\n",
    "        return output\n",
    "\n",
    "class FreqNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FreqNet, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(WINDOW_SIZE, 64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        output = self.main(noise)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cabba33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting training data\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Creating a batch generator\n",
      "Done creating batch generator\n",
      "Collected\n",
      "Round 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1036 is out of bounds for axis 0 with size 1024",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFreq MSB last pred:\u001b[39m\u001b[38;5;124m\"\u001b[39m, prediction_freq_msb, data_test_freq_msb)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], time_generator\u001b[38;5;241m.\u001b[39meval(), channel_generator\u001b[38;5;241m.\u001b[39meval(), command_generator\u001b[38;5;241m.\u001b[39meval(), freq_lsb_generator\u001b[38;5;241m.\u001b[39meval(), freq_msb_generator\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 127\u001b[0m seed, time_generator, channel_generator, command_generator, freq_lsb_generator, freq_msb_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpred_cmd\u001b[39m(offset, cmd_pred):\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m offset \u001b[38;5;241m==\u001b[39m cmd_pred\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m freq_lsb_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     56\u001b[0m freq_msb_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 58\u001b[0m data_train_cmd, data_train_time, data_train_freq_lsb, data_train_freq_msb \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m data_test \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     61\u001b[0m data_test_time \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39marray([[data_test[\u001b[38;5;241m0\u001b[39m]]]))\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat)\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mprepare_data_train\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data_train\u001b[39m(data):\n\u001b[1;32m      9\u001b[0m     data_train_cmd\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39marray([data]))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m     data_train_time \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39marray([[data[(i \u001b[38;5;241m*\u001b[39m NUM_INP) \u001b[38;5;241m+\u001b[39m TIME_OFFSET] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(WINDOW_SIZE)]]))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m     data_train_freq_lsb \u001b[38;5;241m=\u001b[39m extract_and_pad(data, CMD_LSB, FREQLSB_OFFSET)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     data_train_freq_msb \u001b[38;5;241m=\u001b[39m extract_and_pad(data, CMD_MSB, FREQMSB_OFFSET)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data_train\u001b[39m(data):\n\u001b[1;32m      9\u001b[0m     data_train_cmd\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39marray([data]))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m     data_train_time \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39marray([[\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNUM_INP\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTIME_OFFSET\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(WINDOW_SIZE)]]))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m     data_train_freq_lsb \u001b[38;5;241m=\u001b[39m extract_and_pad(data, CMD_LSB, FREQLSB_OFFSET)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     data_train_freq_msb \u001b[38;5;241m=\u001b[39m extract_and_pad(data, CMD_MSB, FREQMSB_OFFSET)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1036 is out of bounds for axis 0 with size 1024"
     ]
    }
   ],
   "source": [
    "def extract_and_pad(data, cmd, field_offset):\n",
    "    new_data = np.array([data[(i * NUM_INP) + field_offset] for i in range(WINDOW_SIZE) if data[(i * NUM_INP) + CMD_OFFSET] == cmd])\n",
    "    new_data = np.pad(new_data, pad_width=(0, WINDOW_SIZE - len(new_data)))\n",
    "    new_data = torch.Tensor(np.array([new_data]))\n",
    "    return new_data\n",
    "\n",
    "def prepare_data_train(data):\n",
    "\n",
    "    data_train_cmd= torch.Tensor(np.array([data])).to(device)\n",
    "    data_train_time = torch.Tensor(np.array([[data[(i * NUM_INP) + TIME_OFFSET] for i in range(WINDOW_SIZE)]])).to(device)\n",
    "    data_train_freq_lsb = extract_and_pad(data, CMD_LSB, FREQLSB_OFFSET).to(device)\n",
    "    data_train_freq_msb = extract_and_pad(data, CMD_MSB, FREQMSB_OFFSET).to(device)\n",
    "\n",
    "    return data_train_cmd, data_train_time, data_train_freq_lsb, data_train_freq_msb\n",
    "\n",
    "\n",
    "def train():\n",
    "    \n",
    "    lr=0.0001\n",
    "\n",
    "    time_generator = TimeNet().to(device)\n",
    "    time_optimizer= optim.Adam(time_generator.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    time_criterion = nn.MSELoss()\n",
    "\n",
    "    channel_generator = ChannelNet().to(device)\n",
    "    channel_optimizer= optim.Adam(channel_generator.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    channel_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    command_generator = CommandNet().to(device)\n",
    "    command_optimizer= optim.Adam(command_generator.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    command_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # The two frequency generators are trained when we are predicting a\n",
    "    # frequency command only\n",
    "    freq_msb_generator = FreqNet().to(device)\n",
    "    freq_msb_optimizer = optim.Adam(command_generator.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    freq_msb_criterion = nn.MSELoss()\n",
    "\n",
    "    freq_lsb_generator = FreqNet().to(device)\n",
    "    freq_lsb_optimizer = optim.Adam(command_generator.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    freq_lsb_criterion = nn.MSELoss()\n",
    "\n",
    "    print(\"Collecting training data\")\n",
    "    train_gen = create_data_split(training_files(\"../..//training_data/\"), 1)\n",
    "    print(\"Collected\")\n",
    "\n",
    "    for iteration in range(EPOCHS):\n",
    "        print(f\"Round {iteration}\")\n",
    "\n",
    "        for i in range(ROUND_SZ):\n",
    "          data = next(train_gen)\n",
    "\n",
    "          time_optimizer.zero_grad()\n",
    "          command_optimizer.zero_grad()\n",
    "          freq_lsb_optimizer.zero_grad()\n",
    "          freq_msb_optimizer.zero_grad()\n",
    "\n",
    "          data_train_cmd, data_train_time, data_train_freq_lsb, data_train_freq_msb = prepare_data_train(data['X'][0])\n",
    "\n",
    "          data_test = data['Y'][0]\n",
    "          data_test_time = torch.Tensor(np.array([[data_test[0]]])).to(torch.float)\n",
    "          data_test_channel = torch.Tensor(np.array([data_test[1:3]]))\n",
    "          data_test_command= torch.Tensor(np.array([onehot_cmd(data_test)]))\n",
    "\n",
    "          data_test_freq_lsb = torch.Tensor(np.array([[data_test[FREQLSB_OFFSET]]]))\n",
    "          data_test_freq_msb = torch.Tensor(np.array([[data_test[FREQMSB_OFFSET]]]))\n",
    "\n",
    "          count = 0\n",
    "          for x in data_test_command[0]:\n",
    "              if x.item() == 1.:\n",
    "                  count += 1\n",
    "          if count > 1:\n",
    "              raise \"count?!?!?\"\n",
    "\n",
    "          if CUDA:\n",
    "              data_test_time = data_test_time.cuda()\n",
    "              data_test_channel = data_test_channel.cuda()\n",
    "              data_test_command = data_test_command.cuda()\n",
    "              data_test_freq_lsb = data_test_freq_lsb.cuda()\n",
    "              data_test_freq_msb = data_test_freq_msb.cuda()\n",
    "\n",
    "          prediction_time = time_generator(data_train_time)\n",
    "\n",
    "          #print(\"TRAIN\", data_train)\n",
    "          #print(\"TEST\", prediction_time, data_test_time)\n",
    "          time_loss = time_criterion(prediction_time, data_test_time)\n",
    "          time_loss.backward()\n",
    "          time_optimizer.step()\n",
    "\n",
    "          time_ltgt = data_test_time\n",
    "          time_lpred = prediction_time\n",
    "\n",
    "          prediction_command = command_generator(data_train_cmd)\n",
    "          #print(prediction_command.flatten(), data_test_command.flatten())\n",
    "          command_loss = command_criterion(prediction_command, data_test_command)\n",
    "          command_loss.backward()\n",
    "          command_optimizer.step()\n",
    "\n",
    "          command_ltgt = data_test_command\n",
    "          command_lpred = prediction_command\n",
    "\n",
    "          if data_test[CMD_LSB] == 1.:\n",
    "              #print(\"Train LSB\")\n",
    "              prediction_freq_lsb = freq_lsb_generator(data_train_freq_lsb)\n",
    "              freq_lsb_loss = freq_lsb_criterion(prediction_freq_lsb, data_test_freq_lsb)\n",
    "              freq_lsb_loss.backward()\n",
    "              freq_lsb_optimizer.step()\n",
    "\n",
    "          if data_test[CMD_MSB] == 1.:\n",
    "              #print(\"Train MSB\")\n",
    "              prediction_freq_msb = freq_msb_generator(data_train_freq_msb)\n",
    "              freq_msb_loss = freq_msb_criterion(prediction_freq_msb, data_test_freq_msb)\n",
    "              freq_msb_loss.backward()\n",
    "              freq_msb_optimizer.step()\n",
    "\n",
    "        print(\"Time batch loss:\", time_loss.item())\n",
    "        print(\"Last prediction:\", time_ltgt, time_lpred)\n",
    "        print(\"Command batch loss:\", command_loss.item())\n",
    "        print(\"Last prediction:\", command_ltgt, command_lpred)\n",
    "        print(\"Freq LSB loss:\", freq_lsb_loss.item())\n",
    "        print(\"Freq LSB last pred:\", prediction_freq_lsb, data_test_freq_lsb)\n",
    "        print(\"Freq MSB loss:\", freq_msb_loss.item())\n",
    "        print(\"Freq MSB last pred:\", prediction_freq_msb, data_test_freq_msb)\n",
    "\n",
    "    return data['X'][0], time_generator.eval(), channel_generator.eval(), command_generator.eval(), freq_lsb_generator.eval(), freq_msb_generator.eval()\n",
    "\n",
    "seed, time_generator, channel_generator, command_generator, freq_lsb_generator, freq_msb_generator = train()\n",
    "\n",
    "def pred_cmd(offset, cmd_pred):\n",
    "    return offset == cmd_pred.argmax().item()\n",
    "\n",
    "for i in range(10000):\n",
    "\n",
    "    data_train_cmd, data_train_time, data_train_freq_lsb, data_train_freq_msb = prepare_data_train(seed)\n",
    "\n",
    "    next_channel = channel_generator(data_train_cmd)\n",
    "\n",
    "    if pred_cmd(CH_1_OFFSET - 1, next_channel):\n",
    "        next_channel = 1\n",
    "    elif pred_cmd(CH_2_OFFSET - 1, next_channel):\n",
    "        next_channel = 2\n",
    "\n",
    "    next_time = unnorm(time_generator(data_train_time)[0].item(), NORMALIZE_TIME_BY)\n",
    "    next_cmd = command_generator(data_train_cmd)\n",
    "\n",
    "    #print(next_time)\n",
    "    #print(next_cmd)\n",
    "\n",
    "    print(\"Next cmd\", next_cmd)\n",
    "\n",
    "    if pred_cmd(NOP_CMD_OFFSET - 3, next_cmd):\n",
    "        fresh = nop()\n",
    "        print(\"NOP - WHY DID I PREDICT A NO-OP?\")\n",
    "    elif pred_cmd(DUTY_LL_CMD_OFFSET - 3, next_cmd):\n",
    "        fresh = duty_ll(1, [0, 0, 0, 0, 0, 0, 0], next_time)\n",
    "        print(\"DUTY LL TODO\")\n",
    "    elif pred_cmd(VOLENVPER_CMD_OFFSET - 3, next_cmd):\n",
    "        fresh = volenvper(1, [0, 0, 0, 0, 0, 0, 0], next_time)\n",
    "        print(\"VOLENVPER TODO\")\n",
    "    elif pred_cmd(FREQMSB_CMD_OFFSET - 3, next_cmd):\n",
    "        pred = freq_msb_generator(data_train_freq_msb)[0].item()\n",
    "        fresh = freqmsb(1, [0, 0, 0, unnorm(pred, 7.), 0, 0], next_time)\n",
    "        print(\"FREQMSB AT \", next_time, unnorm(pred, 7.))\n",
    "    elif pred_cmd(FREQLSB_CMD_OFFSET - 3, next_cmd):\n",
    "        pred = freq_lsb_generator(data_train_freq_msb)[0].item()\n",
    "        fresh = freqlsb(1, [0, 0, 0, unnorm(pred, 255.), 0, 0], next_time)\n",
    "        print(f\"FREQLSB {unnorm(pred, 255.)} AT {next_time}\")\n",
    "    else:\n",
    "        print(\"??\")\n",
    "\n",
    "    seed = np.concatenate((seed[NUM_INP:], fresh))\n",
    "    #print(\"new seed\", seed)\n",
    "    #print(fresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd94ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
