{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec8ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pescador\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch.distributions.normal import Normal\n",
    "from local_attention import LocalAttention\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import math\n",
    "\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from functools import reduce\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.distributions.one_hot_categorical import OneHotCategorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a429bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger('gbsd')\n",
    "LOGGER.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b16da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c20fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdbf4a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88c156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD_VOLENVPER = 0\n",
    "CMD_DUTYLL = 1\n",
    "CMD_MSB = 2\n",
    "CMD_LSB = 3\n",
    "CMD_COUNT = 4\n",
    "\n",
    "TIME_OFFSET = 0\n",
    "CH_OFFSET = 1\n",
    "CMD_OFFSET = 2\n",
    "PARAM1_OFFSET = 3\n",
    "PARAM2_OFFSET = 4\n",
    "PARAM3_OFFSET = 5\n",
    "SIZE_OF_INPUT_FIELDS = 6\n",
    "\n",
    "MAX_WINDOW_SIZE = 2 * 1024\n",
    "\n",
    "M_CYCLES_PER_SECOND = 4194304.\n",
    "NORMALIZE_TIME_BY = M_CYCLES_PER_SECOND * 10.\n",
    "\n",
    "def fresh_input(command, channel, time):\n",
    "    newd = np.zeros(shape=SIZE_OF_INPUT_FIELDS, dtype=int)\n",
    "    newd[TIME_OFFSET] = time\n",
    "    newd[CH_OFFSET] = channel\n",
    "    newd[CMD_OFFSET] = command\n",
    "    return newd\n",
    "\n",
    "def parse_bool(v):\n",
    "    if v == \"true\":\n",
    "        return 1\n",
    "    elif v == \"false\":\n",
    "        return 0\n",
    "    else:\n",
    "        return int(v)\n",
    "\n",
    "def command_of_parts(command, channel, parts, time):\n",
    "    inp = fresh_input(command, channel, time)\n",
    "    \n",
    "    if command == CMD_DUTYLL:\n",
    "        inp[PARAM1_OFFSET] = int(parts[3])\n",
    "        inp[PARAM2_OFFSET] = int(parts[4])\n",
    "    elif command == CMD_VOLENVPER:\n",
    "        inp[PARAM1_OFFSET] = int(parts[3])\n",
    "        inp[PARAM2_OFFSET] = parse_bool(parts[4])\n",
    "        inp[PARAM3_OFFSET] = int(parts[4])\n",
    "    elif command == CMD_LSB:\n",
    "        inp[PARAM1_OFFSET] = int(parts[3])\n",
    "        inp[PARAM2_OFFSET] = 0\n",
    "        inp[PARAM3_OFFSET] = 0\n",
    "    elif command == CMD_MSB:\n",
    "        inp[PARAM1_OFFSET] = int(parts[3])\n",
    "        inp[PARAM2_OFFSET] = parse_bool(parts[4])\n",
    "        inp[PARAM3_OFFSET] = parse_bool(parts[5])\n",
    "    else:\n",
    "        raise \"this should not happen\"\n",
    "    return inp\n",
    "\n",
    "def int32_as_bytes(ival):\n",
    "    return np.frombuffer(ival.item().to_bytes(4, byteorder = 'big'), dtype=np.uint8)\n",
    "\n",
    "def int32_of_bytes(np):\n",
    "    return int.from_bytes(np, byteorder = 'big')\n",
    "\n",
    "def int8_as_bytes(ival):\n",
    "    return np.frombuffer(ival.item().to_bytes(1, byteorder='big'), dtype=np.uint8)\n",
    "\n",
    "def int8_of_bytes(np):\n",
    "    return int.from_bytes(np, byteorder = 'big')\n",
    "\n",
    "def merge_params(data):\n",
    "    command = data[CMD_OFFSET]\n",
    "    if command == CMD_DUTYLL:\n",
    "        return (data[PARAM1_OFFSET] << 6) | data[PARAM2_OFFSET]\n",
    "    elif command == CMD_VOLENVPER:\n",
    "        return (data[PARAM1_OFFSET] << 4) | (data[PARAM2_OFFSET] << 3) | data[PARAM3_OFFSET]\n",
    "    elif command == CMD_LSB:\n",
    "        return data[PARAM1_OFFSET]\n",
    "    elif command == CMD_MSB:\n",
    "        return data[PARAM1_OFFSET]  | (data[PARAM2_OFFSET] << 6) | (data[PARAM3_OFFSET] << 7)\n",
    "    else:\n",
    "        raise \"this should not happen\"\n",
    "        \n",
    "def unmerge_params(command, data,v ):\n",
    "    if command == CMD_DUTYLL:\n",
    "        data[PARAM1_OFFSET] = v >> 6;\n",
    "        data[PARAM2_OFFSET] = v & 0b0011_1111\n",
    "    elif command == CMD_VOLENVPER:\n",
    "        data[PARAM1_OFFSET] = v >> 4\n",
    "        data[PARAM2_OFFSET] = (v & 0b0000_1000) >> 3\n",
    "        data[PARAM3_OFFSET] = (v & 0b0000_0111)\n",
    "    elif command == CMD_LSB:\n",
    "        data[PARAM1_OFFSET] = v\n",
    "    elif command == CMD_MSB:\n",
    "        data[PARAM1_OFFSET] = v & 0b0011_1111\n",
    "        data[PARAM2_OFFSET] = (v & 0b0100_0000) >> 6\n",
    "        data[PARAM3_OFFSET] = (v & 0b1000_0000) >> 7\n",
    "    else:\n",
    "        raise Exception(\"this should not happen\")\n",
    "        \n",
    "BYTES_PER_ENTRY=7\n",
    "\n",
    "def command_to_bytes(command):\n",
    "    new_arr = np.concatenate([\n",
    "                    int32_as_bytes(command[TIME_OFFSET]),\n",
    "                    int8_as_bytes(command[CH_OFFSET]),\n",
    "                    int8_as_bytes(command[CMD_OFFSET]),\n",
    "                    int8_as_bytes(merge_params(command)),]).flatten()\n",
    "    return new_arr\n",
    "\n",
    "def command_of_bytes(byte_arr):\n",
    "    d = fresh_input(0, 0, 0)\n",
    "    d[TIME_OFFSET] = int32_of_bytes(byte_arr[0:4])\n",
    "    d[CH_OFFSET] = int8_of_bytes(byte_arr[4:5])\n",
    "    if d[CH_OFFSET] != 1 and d[CH_OFFSET] != 2:\n",
    "        raise Exception(\"bad channel prediction\")\n",
    "    d[CMD_OFFSET] = int8_of_bytes(byte_arr[5:6])\n",
    "    unmerge_params(d[CMD_OFFSET], d, byte_arr[6])\n",
    "    return d\n",
    "\n",
    "def print_feature(data, file=sys.stdout):\n",
    "    command = data[CMD_OFFSET]\n",
    "    if command == CMD_DUTYLL:\n",
    "        print(f\"CH {data[CH_OFFSET]} DUTYLL {data[PARAM1_OFFSET]} {data[PARAM2_OFFSET]} AT {data[TIME_OFFSET]}\", file=file, flush=True)\n",
    "    elif command == CMD_VOLENVPER:\n",
    "        print(f\"CH {data[CH_OFFSET]} VOLENVPER {data[PARAM1_OFFSET]} {data[PARAM2_OFFSET]} {data[PARAM3_OFFSET]} AT {data[TIME_OFFSET]}\", file=file, flush=True)\n",
    "    elif command == CMD_LSB:\n",
    "        print(f\"CH {data[CH_OFFSET]} FREQLSB {data[PARAM1_OFFSET]} AT {data[TIME_OFFSET]}\", file=file, flush=True)\n",
    "    elif command == CMD_MSB:\n",
    "        print(f\"CH {data[CH_OFFSET]} FREQMSB {data[PARAM1_OFFSET]} {data[PARAM2_OFFSET]} {data[PARAM3_OFFSET]} AT {data[TIME_OFFSET]}\", file=file, flush=True)\n",
    "    else:\n",
    "        print(f\"Bad prediction\", file=file, flush=True)\n",
    "\n",
    "def load_training_data(src):\n",
    "    data = []\n",
    "    file = open(src, 'r')\n",
    "    for line in file:\n",
    "        parts = line.split()\n",
    "        if len(parts) > 0 and parts[0] == \"CH\":\n",
    "            #print(parts)\n",
    "            channel = int(parts[1])\n",
    "            command = parts[2]\n",
    "            time = int(parts[-1])\n",
    "            if command == \"DUTYLL\":\n",
    "                new_item = command_of_parts(CMD_DUTYLL, channel, parts, time)\n",
    "            elif command == \"VOLENVPER\":\n",
    "                new_item = command_of_parts(CMD_VOLENVPER, channel, parts, time)\n",
    "            elif command == \"FREQLSB\":\n",
    "                new_item = command_of_parts(CMD_LSB, channel, parts, time)\n",
    "            elif command == \"FREQMSB\":\n",
    "                new_item = command_of_parts(CMD_MSB, channel, parts, time)\n",
    "            else:\n",
    "                print(\"Unknown\", command)\n",
    "             # Otherwise unknown   \n",
    "            data.append(new_item)\n",
    "    return data\n",
    "\n",
    "@pescador.streamable\n",
    "def samples_from_training_data(src, window_size, start_at_sample):\n",
    "    \n",
    "    # Scale the window size by the bytes per entry\n",
    "    window_size = window_size * BYTES_PER_ENTRY\n",
    "    \n",
    "    sample_data = None\n",
    "    try:\n",
    "        sample_data = load_training_data(src)\n",
    "    except Exception as e:\n",
    "        LOGGER.error('Could not load {}: {}'.format(src, str(e)))\n",
    "        raise StopIteration()\n",
    "        \n",
    "    sample_data = np.array([command_to_bytes(x) for x in sample_data]).flatten()\n",
    "\n",
    "    while True:\n",
    "        if len(sample_data) < window_size:\n",
    "            sample = sample_data\n",
    "        else:\n",
    "            # Sample a random window from the audio file\n",
    "            start_idx = np.random.randint(0, len(sample_data) - window_size)\n",
    "            \n",
    "            # If we should start on a sample boundary then round to the nearest multiple of sample boundary from the start\n",
    "            if start_at_sample:\n",
    "                start_idx = BYTES_PER_ENTRY * round(start_idx / BYTES_PER_ENTRY)\n",
    "\n",
    "            sample = sample_data[start_idx:(start_idx + window_size)]\n",
    "\n",
    "        yield sample\n",
    "\n",
    "def create_batch_generator(paths, window_size, start_at_sample):\n",
    "    streamers = []\n",
    "    \n",
    "    for path in paths:\n",
    "        streamers.append(samples_from_training_data(path, window_size, start_at_sample))\n",
    "    \n",
    "    mux = pescador.StochasticMux(streamers, n_active=1, rate=1).iterate()\n",
    "    \n",
    "    return mux\n",
    "\n",
    "def training_files(dirp):\n",
    "    return [\n",
    "      os.path.join(root, fname)\n",
    "      for (root, dir_names, file_names) in os.walk(dirp, followlinks=True)\n",
    "      for fname in file_names\n",
    "    ]\n",
    "\n",
    "def create_data_split(paths, window_size=MAX_WINDOW_SIZE, start_at_sample=True):\n",
    "    train_gen = create_batch_generator(paths, window_size, start_at_sample)\n",
    "    return train_gen\n",
    "\n",
    "class SampleDataset(torch.utils.data.IterableDataset):\n",
    "    \n",
    "    def __init__(self, path, window_size):\n",
    "        super(SampleDataset).__init__()\n",
    "        \n",
    "        files = training_files(path)\n",
    "        \n",
    "        print(\"Training files: \", files)\n",
    "        \n",
    "        # Add one to window_size so that we have window size labels and inputs\n",
    "        self.loader = create_data_split(files, window_size=MAX_WINDOW_SIZE + 1, start_at_sample=False)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "             yield next(self.loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "526c9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout = 0.1, max_len = 2048):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert(MAX_WINDOW_SIZE <= max_len)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7afa9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_SIZE_SAMPLES=16\n",
    "KERNEL_SIZE=BYTES_PER_ENTRY * KERNEL_SIZE_SAMPLES\n",
    "NUM_LAYERS=4\n",
    "RECEPTIVE_FIELD_BYTES=KERNEL_SIZE*(2**4)\n",
    "\n",
    "class CausalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, **kwargs):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "        self.pad = (kernel_size - 1) * dilation\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size , dilation=dilation, **kwargs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #pad here to only add to the left side\n",
    "        x = F.pad(x, (self.pad, 0))\n",
    "        return self.conv(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel_size, skip_channels, dilation=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv_sig = CausalConv1d(input_channels, output_channels, kernel_size, dilation)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        self.conv_tan = CausalConv1d(input_channels, output_channels, kernel_size, dilation)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        #separate weights for residual and skip channels\n",
    "        self.conv_r = nn.Conv1d(output_channels, output_channels, 1)\n",
    "        self.conv_s = nn.Conv1d(output_channels, skip_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.sig(self.conv_sig(x)) * self.tanh(self.conv_tan(x))\n",
    "        skip = self.conv_s(o)\n",
    "        residual = self.conv_r(o)\n",
    "        return residual, skip\n",
    "    \n",
    "class AttentionResBlock(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel_size, skip_channels, dilation=1):\n",
    "        super(AttentionResBlock, self).__init__()\n",
    "        \n",
    "        self.attn_sig = LocalAttention(window_size=512, dim=input_channels, causal=True)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        self.attn_tan = LocalAttention(window_size=512, dim=input_channels, causal=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        #separate weights for residual and skip channels\n",
    "        self.conv_r = nn.Conv1d(output_channels, output_channels, 1)\n",
    "        self.conv_s = nn.Conv1d(output_channels, skip_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.sig(self.attn_sig(x)) * self.tanh(self.attn_tan(x))\n",
    "        skip = self.conv_s(o)\n",
    "        residual = self.conv_r(o)\n",
    "        return residual, skip\n",
    "    \n",
    "class AttentionNet(nn.Module):\n",
    "    def __init__(self, skip_channels=256, num_blocks=4, num_layers=5, num_hidden=256, kernel_size=KERNEL_SIZE): \n",
    "        super(AttentionNet, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(skip_channels, skip_channels)\n",
    "        self.positional_embedding = PositionalEncoding(skip_channels)\n",
    "        self.causal_conv = CausalConv1d(skip_channels, num_hidden, kernel_size)\n",
    "        self.res_stack = nn.ModuleList()\n",
    "\n",
    "        for b in range(num_blocks):\n",
    "            for i in range(num_layers):\n",
    "                self.res_stack.append(AttentionResBlock(num_hidden, num_hidden, kernel_size, skip_channels=skip_channels, dilation=2**i))\n",
    "        \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv1d(skip_channels, skip_channels, 1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(skip_channels, skip_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        o = self.embed(x)\n",
    "        o = self.positional_embedding(o)\n",
    "        o = o.permute(0,2,1)\n",
    "        \n",
    "        o = self.causal_conv(o)\n",
    "        \n",
    "        skip_vals = []\n",
    "        \n",
    "        #run res blocks\n",
    "        for i, layer in enumerate(self.res_stack):\n",
    "            o, s = layer(o)\n",
    "            skip_vals.append(s)\n",
    "            \n",
    "        #sum skip values and pass to last portion of network\n",
    "        o = reduce((lambda a,b: a+b), skip_vals)\n",
    "        \n",
    "        o = self.relu1(o)\n",
    "        o = self.conv1(o)\n",
    "        o = self.relu2(o)\n",
    "        o = self.conv2(o)\n",
    "        \n",
    "        return o\n",
    "\n",
    "# When using dilations the effective lookback is KERNEL_SIZE^num_layers\n",
    "class CommandNet(nn.Module):\n",
    "    def __init__(self, skip_channels=256, num_blocks=2, num_layers=NUM_LAYERS, num_hidden=256, kernel_size=KERNEL_SIZE): \n",
    "        super(CommandNet, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(skip_channels, skip_channels)\n",
    "        self.positional_embedding = PositionalEncoding(skip_channels)\n",
    "        self.causal_conv = CausalConv1d(skip_channels, num_hidden, kernel_size)\n",
    "        self.res_stack = nn.ModuleList()\n",
    "\n",
    "        for b in range(num_blocks):\n",
    "            for i in range(num_layers):\n",
    "                self.res_stack.append(ResidualBlock(num_hidden, num_hidden, kernel_size, skip_channels=skip_channels, dilation=2**i))\n",
    "        \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv1d(skip_channels, skip_channels, 1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(skip_channels, skip_channels, 1)\n",
    "        \n",
    "    # TODO: Move the receptive field here\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        o = self.embed(x)\n",
    "        o = self.positional_embedding(o)\n",
    "        o = o.permute(0,2,1)\n",
    "        \n",
    "        o = self.causal_conv(o)\n",
    "        \n",
    "        skip_vals = []\n",
    "        \n",
    "        #run res blocks\n",
    "        for i, layer in enumerate(self.res_stack):\n",
    "            o, s = layer(o)\n",
    "            skip_vals.append(s)\n",
    "            \n",
    "        #sum skip values and pass to last portion of network\n",
    "        o = reduce((lambda a,b: a+b), skip_vals)\n",
    "        \n",
    "        o = self.relu1(o)\n",
    "        o = self.conv1(o)\n",
    "        o = self.relu2(o)\n",
    "        o = self.conv2(o)\n",
    "        \n",
    "        return o\n",
    "\n",
    "def load(path):\n",
    "        \n",
    "    lr = 0.01\n",
    "    momentum=0.8\n",
    "    \n",
    "    command_generator = CommandNet()\n",
    "    \n",
    "    optimizer = optim.SGD(\n",
    "        command_generator.parameters(),\n",
    "        lr=lr,\n",
    "        momentum=momentum\n",
    "    )\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.97, min_lr=0.0001)\n",
    "    command_generator = command_generator.to(device)\n",
    "    \n",
    "    # This needs to be after to because the optimizer decides what device to send the tensors to based on the\n",
    "    # device of the model.\n",
    "    if path != None:\n",
    "        command_generator.load_state_dict(torch.load(path + \".model\"))\n",
    "        optimizer.load_state_dict(torch.load(path + \".optimizer\"))\n",
    "        #scheduler = torch.load(path + \".scheduler\")\n",
    "\n",
    "    return command_generator, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c61214",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting training data\n",
      "Training files:  ['../../training_data/harvest_title', '../../training_data/tetris_world_music_a', '../../training_data/tetris_2_game_menu_b', '../../training_data/barbie', '../../training_data/casper', '../../training_data/pk_oak', '../../training_data/zelda_title', '../../training_data/star_wars_return_of_the_jedi_title', '../../training_data/tetris_attack', '../../training_data/tetris_attack_ingame', '../../training_data/tetris_world', '../../training_data/batman_return_of_the_joker_title', '../../training_data/star_wars_return_of_the_jedi_ingame', '../../training_data/aliens_into', '../../training_data/kirbys_dreamland_title', '../../training_data/knights_quest_title', '../../training_data/toy_story_menu', '../../training_data/star_wars_title', '../../training_data/pk_title', '../../training_data/batman_forever_title', '../../training_data/bubble_ghost_ingame', '../../training_data/tetris_attack_menu', '../../training_data/lion_king_menu', '../../training_data/simpsons_bart_and_beanstalk_title', '../../training_data/dick_tracy_ingame', '../../training_data/simpsons_bart_and_beanstalk_menu', '../../training_data/tmnt_ingame', '../../training_data/tmnt_menu', '../../training_data/tetris_2_startup', '../../training_data/tetris_world_music_b', '../../training_data/aladdin_ingame', '../../training_data/casper_menu', '../../training_data/shaq_fu_title', '../../training_data/lemmings_ingame', '../../training_data/dk_ingame', '../../training_data/toy_story_title', '../../training_data/toy_story_ingame', '../../training_data/knights_quest_ingame', '../../training_data/tetris_2_game_menu', '../../training_data/tetris_world_music_c', '../../training_data/dk_title', '../../training_data/tetris_2_game_menu_c', '../../training_data/aladdin_title', '../../training_data/lion_king_intro', '../../training_data/language_translator', '../../training_data/bubble_ghost', '../../training_data/wwf', '../../training_data/adventures_of_lolo/tutorial_snakey', '../../training_data/adventures_of_lolo/title', '../../training_data/adventures_of_lolo/tutorial_snakey_us_playing', '../../training_data/adventures_of_lolo/tutorial_intro', '../../training_data/adventures_of_lolo/welcome_to_puzzle_land', '../../training_data/adventures_of_lolo/menu', '../../training_data/adventures_of_lolo/leeper_tutorial', '../../training_data/attack_of_the_killer_tomatoes/title', '../../training_data/attack_of_the_killer_tomatoes/stage_1', '../../training_data/adventures_of_star_saver/stage_1', '../../training_data/bo_jackson_hit_and_run/title', '../../training_data/amazing_tater/beginner', '../../training_data/amazing_tater/beginner_ingame', '../../training_data/amazing_tater/beginner_postgame', '../../training_data/amazing_tater/title', '../../training_data/amazing_tater/menu', '../../training_data/best_of_the_best_karate/title', '../../training_data/all_star_baseball_99/title', '../../training_data/all_star_baseball_99/menu', '../../training_data/atomic_punk/panel_select', '../../training_data/atomic_punk/title', '../../training_data/atomic_punk/panel_shop', '../../training_data/atomic_punk/world_select', '../../training_data/atomic_punk/forest', '../../training_data/aerostar/title', '../../training_data/asteroids/title', '../../training_data/buster_brothers/level_1_main', '../../training_data/buster_brothers/title', '../../training_data/buster_brothers/level_1_intro', '../../training_data/beetlejuice/title', '../../training_data/bionic_battler/title', '../../training_data/bill_elliotts_nascar_fast_tracks/title', '../../training_data/bill_elliotts_nascar_fast_tracks/menu', '../../training_data/bill_elliotts_nascar_fast_tracks/select_driver', '../../training_data/adventure_island/title', '../../training_data/adventure_island/level_1', '../../training_data/black_bass_lure_fishing/title', '../../training_data/black_bass_lure_fishing/menu', '../../training_data/bases_loaded/title', '../../training_data/battletoads_double_dragon/title', '../../training_data/adventures_of_rocky_and_bullwinkle/title', '../../training_data/adventures_of_rocky_and_bullwinkle/menu', '../../training_data/asteriods/title', '../../training_data/blaster_master_boy/stage_1', '../../training_data/bomb_jack/title', '../../training_data/bomberman_gb/title', '../../training_data/blades_of_steel/title', '../../training_data/blades_of_steel/you_lose', '../../training_data/beethovens_2nd/title', '../../training_data/beethovens_2nd/stage_1', '../../training_data/battleship/title', '../../training_data/battleship/preparing_the_board', '../../training_data/blues_brothers_the_jukebox_adventure/title', '../../training_data/blues_brothers_the_jukebox_adventure/stage_1', '../../training_data/bonks_revenge/title', '../../training_data/bonks_revenge/stage_1', '../../training_data/bonks_adventure/title', '../../training_data/bonks_adventure/stage_1']\n",
      "Collected\n",
      "Starting batch\n",
      "Batch completion: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 500000\n",
    "ROUND_SZ = 100\n",
    "\n",
    "print(\"Collecting training data\")\n",
    "loader = torch.utils.data.DataLoader(SampleDataset(\"../../training_data/\",window_size=MAX_WINDOW_SIZE))\n",
    "print(\"Collected\")\n",
    "\n",
    "def train(path):\n",
    "    \n",
    "    command_generator, optimizer, scheduler = load(path)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    running_loss = torch.zeros(1, device=device)\n",
    "\n",
    "    def step():\n",
    "        \n",
    "        print(\"Starting batch\")\n",
    "        running_loss.zero_()\n",
    "        \n",
    "        for i in range(ROUND_SZ):\n",
    "            \n",
    "            if i % (ROUND_SZ / 10) == 0:\n",
    "                print(\"Batch completion:\", (float(i) / float(ROUND_SZ)) * 100., \"%\")\n",
    "            \n",
    "            seq = next(iter(loader)).long().to(device)\n",
    "            inputs = seq[:,:-1]\n",
    "            labels = seq[:,1:]\n",
    "            \n",
    "            #print(inputs, inputs.shape)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = command_generator(inputs)\n",
    "                \n",
    "                # Backprop only on the datapoints that had at least half a k kernel\n",
    "                #backprop_l = int(min(KERNEL_SIZE / 2, len(seq) / 2))\n",
    "                #backprop_inputs = outputs[:,:,backprop_l:]\n",
    "                #backprop_outputs = labels[:,backprop_l:]\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(loss.detach().item())\n",
    "            running_loss.add_(loss.detach())\n",
    "            #print(running_loss)\n",
    "            \n",
    "            seq = seq.detach().to(cpu)\n",
    "            del inputs\n",
    "            del labels\n",
    "            del seq\n",
    "\n",
    "        result = running_loss / ROUND_SZ\n",
    "        return result\n",
    "    \n",
    "    def save(name):\n",
    "        torch.save(command_generator.state_dict(), \"./\" + name + \".model\")\n",
    "        torch.save(optimizer.state_dict(), \"./\" + name + \".optimizer\")\n",
    "        \n",
    "        # Saving the scheduler seems to break stuff\n",
    "        #torch.save(scheduler, \"./\" + name + \".scheduler\")\n",
    "\n",
    "    for i in range(0, EPOCHS):\n",
    "        loss = step()\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        print(\"Loss:\", loss.item())\n",
    "        print(\"LR:\", optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        print(\"Saving checkpoint\")\n",
    "        \n",
    "        # Timestamp every 10th epoch to test fits later\n",
    "        if i % 10 == 0:\n",
    "            save(str(int(datetime.now().timestamp())))\n",
    "\n",
    "        save(\"./last.checkpoint\")\n",
    "        print(\"Saved checkpoint\")\n",
    "    \n",
    "    return command_generator.eval()\n",
    "\n",
    "#train(None)\n",
    "train(\"./last.checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845221ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Collecting training data\")\n",
    "train_gen = create_data_split(training_files(\"../../out_of_sample/\"))\n",
    "print(\"Collected\")\n",
    "\n",
    "command_generator, _, _ = load(\"./last.checkpoint\")\n",
    "command_generator = command_generator.eval()\n",
    "\n",
    "# Cut the seed to the receptive window of our model so that it executes faster\n",
    "seed = next(train_gen)[:RECEPTIVE_FIELD_BYTES]\n",
    "\n",
    "def max_of(v, begin, end):\n",
    "    return begin + np.argmax(v[begin:end])\n",
    "\n",
    "with open('seed.txt', 'w') as f:\n",
    "    for i in range(0, len(seed), BYTES_PER_ENTRY):\n",
    "        print(\"Seed value :\", i, seed.shape)\n",
    "        cmd = command_of_bytes(seed[i:i+BYTES_PER_ENTRY])\n",
    "        print_feature(cmd, file=f)\n",
    "        \n",
    "class MovingWindow():\n",
    "    \n",
    "    def __init__(self, seed):\n",
    "        # Pre-allocate 16x the seed\n",
    "        self.seq = torch.cat((torch.Tensor(seed).long(), torch.zeros(len(seed) * 16).long())).to(device)\n",
    "        self.start = 0\n",
    "        self.len = len(seed)\n",
    "        \n",
    "    def end(self):\n",
    "        return self.start + self.len\n",
    "        \n",
    "    def append(self, item):\n",
    "        \n",
    "        # when we run out of free slots we move the array by using torch.roll\n",
    "        # so that the data we care about is from 0:len again.\n",
    "        if self.end() == len(self.seq):\n",
    "            # Roll of a 1d Tensor => arr[i] = arr[(i + shift) % len(arr)], so the most recent element \n",
    "            torch.roll(self.seq, self.len)\n",
    "            self.start = 0\n",
    "        else:\n",
    "            self.seq[self.end()] = item\n",
    "            self.start += 1\n",
    "\n",
    "    def window(self):\n",
    "        # Slice the current window\n",
    "        return self.seq[self.start:self.end()]\n",
    "    \n",
    "window = MovingWindow(seed)\n",
    "\n",
    "with open('output.txt', 'w') as f:\n",
    "    \n",
    "    for i in range(BYTES_PER_ENTRY * 10000):\n",
    "        seq = window.window().unsqueeze(0)\n",
    "        pred = command_generator(seq).detach().to(cpu).permute(0,2,1).squeeze(0)[-1]\n",
    "        pred = Categorical(logits=pred).sample()\n",
    "        window.append(pred)\n",
    "    \n",
    "        if (i + 1) % BYTES_PER_ENTRY == 0:\n",
    "            try:\n",
    "                last_sample = window.window()[-BYTES_PER_ENTRY:].detach().cpu().numpy().astype(np.uint8)\n",
    "                last_sample = command_of_bytes(last_sample)\n",
    "                print_feature(last_sample, file=f)\n",
    "            except BaseException as err:\n",
    "                print(\"pred was not valid because:\", err)\n",
    "\n",
    "    del pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8775902c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
