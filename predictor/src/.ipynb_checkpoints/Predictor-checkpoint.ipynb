{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec8ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pescador\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "\n",
    "import gc\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a429bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger('gbsd')\n",
    "LOGGER.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b16da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c20fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdbf4a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88c156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD_VOLENVPER = 0\n",
    "CMD_DUTYLL = 1\n",
    "CMD_MSB = 2\n",
    "CMD_LSB = 3\n",
    "CMD_COUNT = 4\n",
    "\n",
    "def onehot_cmd(data):\n",
    "    cmd = data[CMD_OFFSET]\n",
    "    nd = [ 0, 0, 0, 0 ]\n",
    "    nd[int(cmd)] = 1\n",
    "    return nd\n",
    "\n",
    "\n",
    "CH_1 = 0\n",
    "CH_2 = 1\n",
    "CH_COUNT = 2\n",
    "\n",
    "TIME_OFFSET = 0\n",
    "CH_OFFSET = 1\n",
    "CMD_OFFSET = 2\n",
    "PARAM1_OFFSET = 3\n",
    "PARAM2_OFFSET = 4\n",
    "PARAM3_OFFSET = 5\n",
    "SIZE_OF_INPUT_FIELDS = 6\n",
    "\n",
    "MAX_WINDOW_SIZE = 5000\n",
    "\n",
    "M_CYCLES_PER_SECOND = 4194304.\n",
    "NORMALIZE_TIME_BY = M_CYCLES_PER_SECOND * 10.\n",
    "\n",
    "def norm(val, max_val):\n",
    "    if val > max_val:\n",
    "        return 1.\n",
    "    else:\n",
    "        return ((val / max_val) * 2.) - 1.\n",
    "\n",
    "def unnorm(val, max_val):\n",
    "    return ((val + 1.) / 2.) * max_val\n",
    "\n",
    "def fresh_input(command, channel, time):\n",
    "    newd = np.zeros(shape=SIZE_OF_INPUT_FIELDS, dtype=int)\n",
    "    newd[TIME_OFFSET] = time\n",
    "    newd[CH_OFFSET] = channel\n",
    "    newd[CMD_OFFSET] = command\n",
    "    return newd\n",
    "\n",
    "def parse_bool(v):\n",
    "    if v == \"true\":\n",
    "        return 1\n",
    "    elif v == \"false\":\n",
    "        return 0\n",
    "    else:\n",
    "        return int(v)\n",
    "\n",
    "def command_of_parts(command, channel, parts, time):\n",
    "    inp = fresh_input(command, channel, time)\n",
    "    \n",
    "    if command == CMD_DUTYLL:\n",
    "        inp[PARAM1_OFFSET] = int(parts[3])\n",
    "        inp[PARAM2_OFFSET] = int(parts[4])\n",
    "    elif command == CMD_VOLENVPER:\n",
    "        inp[PARAM1_OFFSET] = int(parts[3])\n",
    "        inp[PARAM2_OFFSET] = parse_bool(parts[4])\n",
    "        inp[PARAM3_OFFSET] = int(parts[4])\n",
    "    elif command == CMD_LSB:\n",
    "        inp[PARAM1_OFFSET] = int(parts[3])\n",
    "        inp[PARAM2_OFFSET] = 0\n",
    "        inp[PARAM3_OFFSET] = 0\n",
    "    elif command == CMD_MSB:\n",
    "        inp[PARAM1_OFFSET] = int(parts[3])\n",
    "        inp[PARAM2_OFFSET] = parse_bool(parts[4])\n",
    "        inp[PARAM3_OFFSET] = parse_bool(parts[5])\n",
    "    else:\n",
    "        raise \"this should not happen\"\n",
    "    return inp\n",
    "\n",
    "def int32_as_bytes(ival):\n",
    "    return np.frombuffer(ival.item().to_bytes(4, byteorder = 'big'), dtype=np.uint8)\n",
    "\n",
    "def int8_as_bytes(ival):\n",
    "    return np.frombuffer(ival.item().to_bytes(1, byteorder='big'), dtype=np.uint8)\n",
    "\n",
    "def merge_params(data):\n",
    "    command = data[CMD_OFFSET]\n",
    "    if command == CMD_DUTYLL:\n",
    "        return (data[PARAM1_OFFSET] << 6) | data[PARAM2_OFFSET]\n",
    "    elif command == CMD_VOLENVPER:\n",
    "        return (data[PARAM1_OFFSET] << 4) | (data[PARAM2_OFFSET] << 3) | data[PARAM3_OFFSET]\n",
    "    elif command == CMD_LSB:\n",
    "        return data[PARAM1_OFFSET]\n",
    "    elif command == CMD_MSB:\n",
    "        return data[PARAM1_OFFSET]  | (data[PARAM2_OFFSET] << 6) | (data[PARAM3_OFFSET] << 7)\n",
    "    else:\n",
    "        raise \"this should not happen\"\n",
    "\n",
    "def command_to_bytes(command):\n",
    "    new_arr = np.concatenate([\n",
    "                    int32_as_bytes(command[TIME_OFFSET]),\n",
    "                    int8_as_bytes(command[CH_OFFSET]),\n",
    "                    int8_as_bytes(command[CMD_OFFSET]),\n",
    "                    int8_as_bytes(merge_params(command)),]).flatten()\n",
    "    return new_arr\n",
    "\n",
    "def unnorm_feature(data):\n",
    "    \n",
    "    data = data.copy()\n",
    "    \n",
    "    # Unnormalize a channel given a specific max value\n",
    "    def l_unnorm(channel, maxv):\n",
    "        data[channel] = unnorm(data[channel], maxv)\n",
    "    \n",
    "    # Round and box a channel to a min and max value\n",
    "    def l_round(channel, minv, maxv):\n",
    "        data[channel] = round(min(max(data[channel], minv), maxv))\n",
    "    \n",
    "    l_unnorm(TIME_OFFSET, NORMALIZE_TIME_BY)\n",
    "    \n",
    "    if data[TIME_OFFSET] < 4:\n",
    "        raise Exception('bad time prediction')\n",
    "    \n",
    "    l_unnorm(CH_OFFSET, CH_COUNT)\n",
    "    data[CH_OFFSET] = round(data[CH_OFFSET])\n",
    "    \n",
    "    l_unnorm(CMD_OFFSET, CMD_COUNT)\n",
    "    data[CMD_OFFSET] = round(data[CMD_OFFSET])\n",
    "    \n",
    "    command = data[CMD_OFFSET]\n",
    "    \n",
    "    if command == CMD_DUTYLL:\n",
    "        l_unnorm(PARAM1_OFFSET, 2)\n",
    "        l_round(PARAM1_OFFSET, 0, 2)\n",
    "        \n",
    "        l_unnorm(PARAM2_OFFSET, 64)\n",
    "        l_round(PARAM2_OFFSET, 0, 64)\n",
    "        \n",
    "        data[PARAM3_OFFSET] = 0.\n",
    "    elif command == CMD_VOLENVPER:\n",
    "        \n",
    "        l_unnorm(PARAM1_OFFSET, 16)\n",
    "        l_round(PARAM1_OFFSET, 0, 16)\n",
    "        \n",
    "        l_round(PARAM2_OFFSET, 0, 1)\n",
    "        \n",
    "        l_unnorm(PARAM3_OFFSET, 7)\n",
    "        l_round(PARAM3_OFFSET, 0, 7)\n",
    "    elif command == CMD_LSB:\n",
    "        \n",
    "        l_unnorm(PARAM1_OFFSET, 255.)\n",
    "        l_round(PARAM1_OFFSET, 0., 255.)\n",
    "        \n",
    "        data[PARAM2_OFFSET] = 0.\n",
    "        \n",
    "        data[PARAM3_OFFSET] = 0.\n",
    "    elif command == CMD_MSB:\n",
    "        l_unnorm(PARAM1_OFFSET, 7.)\n",
    "        l_round(PARAM1_OFFSET, 0., 7.)\n",
    "        \n",
    "        l_round(PARAM2_OFFSET, 0., 1.)\n",
    "        l_round(PARAM3_OFFSET, 0., 1.)\n",
    "    else:\n",
    "        raise Exception(\"pred was bad\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def print_feature(data):\n",
    "    \n",
    "    data = data.copy().astype(int)\n",
    "\n",
    "    data[CH_OFFSET] = data[CH_OFFSET] + 1\n",
    "    command = data[CMD_OFFSET]\n",
    "    \n",
    "    if command == CMD_DUTYLL:\n",
    "        print(f\"CH {data[CH_OFFSET]} DUTYLL {data[PARAM1_OFFSET]} {data[PARAM2_OFFSET]} AT {data[TIME_OFFSET]}\")\n",
    "    elif command == CMD_VOLENVPER:\n",
    "        print(f\"CH {data[CH_OFFSET]} VOLENVPER {data[PARAM1_OFFSET]} {data[PARAM2_OFFSET]} {data[PARAM3_OFFSET]} AT {data[TIME_OFFSET]}\")\n",
    "    elif command == CMD_LSB:\n",
    "        print(f\"CH {data[CH_OFFSET]} FREQLSB {data[PARAM1_OFFSET]} AT {data[TIME_OFFSET]}\")\n",
    "    elif command == CMD_MSB:\n",
    "        print(f\"CH {data[CH_OFFSET]} FREQMSB {data[PARAM1_OFFSET]} {data[PARAM2_OFFSET]} {data[PARAM3_OFFSET]} AT {data[TIME_OFFSET]}\")\n",
    "    else:\n",
    "        print(\"Bad prediction\")\n",
    "\n",
    "def load_training_data(src):\n",
    "    data = []\n",
    "    file = open(src, 'r')\n",
    "    for line in file:\n",
    "        parts = line.split()\n",
    "        if len(parts) > 0 and parts[0] == \"CH\":\n",
    "            #print(parts)\n",
    "            channel = int(parts[1])\n",
    "            command = parts[2]\n",
    "            time = int(parts[-1])\n",
    "            if command == \"DUTYLL\":\n",
    "                new_item = command_of_parts(CMD_DUTYLL, channel, parts, time)\n",
    "            elif command == \"VOLENVPER\":\n",
    "                new_item = command_of_parts(CMD_VOLENVPER, channel, parts, time)\n",
    "            elif command == \"FREQLSB\":\n",
    "                new_item = command_of_parts(CMD_LSB, channel, parts, time)\n",
    "            elif command == \"FREQMSB\":\n",
    "                new_item = command_of_parts(CMD_MSB, channel, parts, time)\n",
    "            else:\n",
    "                print(\"Unknown\", command)\n",
    "             # Otherwise unknown   \n",
    "            data.append(new_item)\n",
    "    return data\n",
    "\n",
    "@pescador.streamable\n",
    "def samples_from_training_data(src, window_size=MAX_WINDOW_SIZE):\n",
    "    sample_data = None\n",
    "    try:\n",
    "        sample_data = load_training_data(src)\n",
    "    except Exception as e:\n",
    "        LOGGER.error('Could not load {}: {}'.format(src, str(e)))\n",
    "        raise StopIteration()\n",
    "\n",
    "    while True:\n",
    "        if len(sample_data) < window_size:\n",
    "            sample = sample_data\n",
    "        else:\n",
    "            # Sample a random window from the audio file\n",
    "            start_idx = np.random.randint(0, len(sample_data) - window_size)\n",
    "            sample = sample_data[start_idx:(start_idx + window_size)]\n",
    "            \n",
    "        sample = np.array([command_to_bytes(x) for x in sample])\n",
    "\n",
    "        yield { 'X':sample }\n",
    "\n",
    "def create_batch_generator(paths, batch_size):\n",
    "    streamers = []\n",
    "    for path in paths:\n",
    "        streamers.append(samples_from_training_data(path))\n",
    "    mux = pescador.StochasticMux(streamers, n_active=1, rate=1).iterate()\n",
    "    \n",
    "    return mux\n",
    "\n",
    "def training_files(dirp):\n",
    "    return [\n",
    "      os.path.join(root, fname)\n",
    "      for (root, dir_names, file_names) in os.walk(dirp, followlinks=True)\n",
    "      for fname in file_names\n",
    "    ]\n",
    "\n",
    "def create_data_split(paths, batch_size):\n",
    "    train_gen = create_batch_generator(paths, batch_size)\n",
    "    return train_gen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45bb8c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting training data\n",
      "Collected\n"
     ]
    }
   ],
   "source": [
    "print(\"Collecting training data\")\n",
    "train_gen = create_data_split(training_files(\"../..//training_data/\"), 1)\n",
    "print(\"Collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b714610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.gamma import Gamma\n",
    "from torch.distributions.normal import Normal\n",
    "import torch\n",
    "\n",
    "class NIGDist():\n",
    "    \n",
    "    def __init__(self, m, vinv, a, b):\n",
    "        self.m = m\n",
    "        self.vinv = vinv\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def update(self, total, moment, n):\n",
    "        \n",
    "        newVinv = self.vinv  + n\n",
    "        newM = (1.0 / newVinv) * (self.vinv * self.m + total)\n",
    "        self.a += n / 2\n",
    "        self.b += 0.5 * (self.m * self.m * self.vinv + moment - newM * newM * newVinv)\n",
    "        self.m = newM\n",
    "        self.vinv = newVinv\n",
    "        \n",
    "        \n",
    "    def update(self, x):\n",
    "        total = torch.sum(x, dim=1)\n",
    "        moment = torch.sum(x * x, dim=1)\n",
    "        n = x.shape[1]\n",
    "        self.update(total, moment, n)\n",
    "\n",
    "    def sample(self):\n",
    "        vars = 1.0 / (Gamma(self.a, self.b)).sample()\n",
    "        means = Normal(self.m, vars / self.vinv).sample()\n",
    "        return means, vars\n",
    "\n",
    "    def update_component(self, index, x):\n",
    "        total = torch.sum(x)\n",
    "        moment = torch.sum(x * x)\n",
    "        n = x.shape[0]\n",
    "        newVinv = self.vinv[index]  + n\n",
    "        newM = (1.0 / newVinv) * (self.vinv[index] * self.m[index] + total)\n",
    "        self.a[index] += n / 2\n",
    "        self.b[index] += 0.5 * (self.m[index] * self.m[index] * self.vinv[index] + moment - newM * newM * newVinv)\n",
    "        self.m[index] = newM\n",
    "        self.vinv[index] = newVinv\n",
    "\n",
    "def standardNIG(batch, device):\n",
    "    return NIGDist(torch.zeros(batch, device=device), torch.ones(batch, device=device), torch.ones(batch, device=device), torch.ones(batch, device=device))\n",
    "\n",
    "class ThompsonTuner():\n",
    "    def __init__(self, stepper, num_options, device):\n",
    "        self.stepper = stepper\n",
    "        self.arms = num_options        \n",
    "        self.belief = standardNIG(self.arms, device)\n",
    "        self.histogram = torch.zeros(self.arms, device=device)\n",
    "        self.n = 0\n",
    "        self.ngpu = torch.zeros(1, device=device)\n",
    "        self.device = device\n",
    "\n",
    "    def step(self):\n",
    "        samples, _ = self.belief.sample()\n",
    "        play = torch.argmax(samples)\n",
    "        obs = self.stepper(play)\n",
    "        self.belief.update_component(play, obs)\n",
    "        self.histogram[play] += 1\n",
    "        self.n += 1\n",
    "        self.ngpu += 1\n",
    "        if self.arms == 2:\n",
    "            pass # Special analytic case\n",
    "        if self.n >= 100:\n",
    "            #print(torch.max(self.histogram) / self.ngpu)\n",
    "            if (torch.max(self.histogram) / self.ngpu) > 0.80:\n",
    "                choice = torch.argmax(self.histogram)\n",
    "                self.stepper.choose(choice)\n",
    "                self.ngpu.zero_()\n",
    "                self.n = 0\n",
    "                self.histogram.zero_()\n",
    "                self.belief.m = self.belief.m[choice].repeat(self.arms)\n",
    "                self.belief.vinv = self.belief.vinv[choice].repeat(self.arms)\n",
    "                self.belief.a = self.belief.a[choice].repeat(self.arms)\n",
    "                self.belief.b = self.belief.b[choice].repeat(self.arms)\n",
    "                self.belief.vinv /= 2\n",
    "                self.belief.a /= 2\n",
    "                self.belief.b /= 2\n",
    "\n",
    "class LRTuner():\n",
    "    #Note: Stepper produces correlated outputs. Take two steps per tuning step to avoid? (Overlapping minibatches?)\n",
    "    class Stepper():\n",
    "        def __init__(self, base):\n",
    "            self.base = base\n",
    "            \n",
    "        def __call__(self, choice):\n",
    "            return self.base.opt(self.base.LRs[choice])\n",
    "            \n",
    "\n",
    "        def choose(self, choice):\n",
    "            #print(\"chose!\")\n",
    "            ratio = self.base.ratio\n",
    "            if choice == 0:\n",
    "                self.base.LRs /= ratio\n",
    "            else:\n",
    "                self.base.LRs *= ratio\n",
    "            \n",
    "    def __init__(self, lr, opt, device, ratio=1.259921049):\n",
    "        self.opt = opt\n",
    "        self.ratio = ratio\n",
    "        self.LRs = torch.tensor([lr, lr * ratio], device=device)\n",
    "        self.tuner = ThompsonTuner(LRTuner.Stepper(self), 2, device)\n",
    "\n",
    "    def step(self):\n",
    "        self.tuner.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddf895b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x, b):\n",
    "    return x * torch.sigmoid(b * x)\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def __init__(self, chan):\n",
    "        super(Swish, self).__init__()\n",
    "        self.register_parameter('weight', nn.Parameter(torch.ones(chan)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return swish(x, self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67a96bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout = 0.1, max_len = MAX_WINDOW_SIZE):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe316a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Functional(nn.Module):\n",
    "    def __init__(self, f):\n",
    "        super(Functional, self).__init__()\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c61214",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3410489966.py, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [13]\u001b[0;36m\u001b[0m\n\u001b[0;31m    + [Functional(lambda x: x.permute(0, 2, 1))]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class CausalConv1d(nn.Conv1d):\n",
    "    # From https://github.com/Straw1239/lang-model-experiments/blob/master/src/main/ConvLM.py\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n",
    "        super(CausalConv1d, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=0,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias)\n",
    "        self.left_padding = dilation * (kernel_size - 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = F.pad(input.unsqueeze(2), (self.left_padding, 0, 0, 0)).squeeze(2)\n",
    "        return super(CausalConv1d, self).forward(x)\n",
    "    \n",
    "class ConvLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLM,self).__init__()\n",
    "        self.embd = nn.Embedding(256, 256)\n",
    "        self.conv1 = CausalConv1d(256, 256, 32, groups=64)\n",
    "        self.conv2 = CausalConv1d(256, 256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embd(x).permute(0,2,1)\n",
    "        x = F.selu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, base):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.base = base\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.base(x)\n",
    "\n",
    "class ApplyConv(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super(ApplyConv, self).__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = x.shape\n",
    "        return self.func(x.view(-1, shape[1])).view(*shape)\n",
    "\n",
    "def res_conv_lm(layers, channels, p_builder, kernel):\n",
    "    spatials = [CausalConv1d(channels, channels, kernel, groups=channels) for _ in range(layers)]\n",
    "    pointwise = [ResBlock(p_builder(i)) for i in range(layers)]\n",
    "    # Interleaving layers of CausalConv1d(...), ResBlock(...), CausalConv1d(...), ResBlock(...)\n",
    "    conv_layers = [layer for pair in zip(spatials, pointwise) for layer in pair]\n",
    "    layers = [nn.Embedding(256, channels), PositionalEncoding(channels)] + [Functional(lambda x: x.permute(0, 2, 1))] + conv_layers + [nn.Conv1d(channels, 256, 1)]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def standard_conv_lm(layers, channels, ksize=8, hfac=4, activation=Swish(1)):\n",
    "    def builder(i):\n",
    "        return nn.Sequential(nn.Conv1d(channels, channels*hfac, 1),\n",
    "                                  activation,\n",
    "                                  nn.Conv1d(channels*hfac, channels, 1))\n",
    "    return res_conv_lm(layers, channels, builder, ksize)\n",
    "\n",
    "def command_net():\n",
    "    return standard_conv_lm(6, 512)\n",
    "\n",
    "EPOCHS = 500000\n",
    "ROUND_SZ = 100\n",
    "\n",
    "def load(path):\n",
    "    command_generator = command_net()\n",
    "    \n",
    "    if path != None:\n",
    "        command_generator.load_state_dict(torch.load(path))\n",
    "        \n",
    "    command_generator = command_generator.to(device)\n",
    "\n",
    "    return command_generator\n",
    "\n",
    "def memReport():\n",
    "    for obj in gc.get_objects():\n",
    "        if torch.is_tensor(obj):\n",
    "            print(type(obj), obj.size())\n",
    "\n",
    "def train(path, baseOpt=optim.SGD, lr=0.001, momentum=0.9, tune_ratio=1.2599, device=torch.device(0)):\n",
    "    \n",
    "    command_generator = load(path)\n",
    "\n",
    "    baseOpt = baseOpt(command_generator.parameters(), lr=lr, momentum=momentum)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    running_loss = torch.zeros(1, device=device)\n",
    "    last_loss = torch.zeros(1, device=device)\n",
    "\n",
    "    def step(lr):\n",
    "        \n",
    "        for i in range(ROUND_SZ):\n",
    "            ntrain =  next(train_gen)['X'].flatten().copy()\n",
    "            seq = torch.Tensor(ntrain).long().to(device)\n",
    "            inputs = seq[:-1].unsqueeze(0)\n",
    "            labels = seq[1:].unsqueeze(0)\n",
    "            \n",
    "            #print(\"Labels:\", labels, labels.shape)\n",
    "    \n",
    "            baseOpt.zero_grad()\n",
    "\n",
    "            for g in baseOpt.param_groups:\n",
    "                g['lr'] = lr\n",
    "\n",
    "            outputs = command_generator(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            baseOpt.step()\n",
    "            running_loss.add_(loss.detach())\n",
    "            \n",
    "            if i == 0:\n",
    "                last_loss.copy_(loss.detach())\n",
    "            result = last_loss - loss.detach()\n",
    "            \n",
    "            seq = seq.detach().to(cpu)\n",
    "            del inputs\n",
    "            del labels\n",
    "            del seq\n",
    "            \n",
    "        return result\n",
    "\n",
    "    opt = LRTuner(lr, step, device, tune_ratio) \n",
    "\n",
    "    for i in range(0, EPOCHS):\n",
    "        opt.step()\n",
    "\n",
    "        print(\"Loss:\", running_loss.item() / ROUND_SZ)\n",
    "        running_loss.zero_()\n",
    "        print(\"LR:\",opt.LRs[0].item())\n",
    "        \n",
    "        print(\"Saving checkpoint\")\n",
    "        torch.save(command_generator.state_dict(), \"./\" + str(int(datetime.now().timestamp())) + \".checkpoint.model\")\n",
    "        torch.save(command_generator.state_dict(), \"./last.checkpoint.model\")\n",
    "        print(\"Saved checkpoint\")\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return command_generator.eval()\n",
    "\n",
    "train(\"./last.checkpoint.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18ca04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%capture cap --no-stderr\n",
    "command_generator = load(\"./last.checkpoint.model\").eval()\n",
    "\n",
    "seed = torch.Tensor(next(train_gen)['X'].flatten().copy()).long().to(device).unsqueeze(0)\n",
    "\n",
    "for i in range(1024):\n",
    "    print(\"Pre pred\", seed)\n",
    "    pred = command_generator(seed).detach().to(cpu).permute(0,2,1).squeeze(0).numpy()\n",
    "    pred = np.array([np.argmax(x) for x in pred])\n",
    "    print(pred, pred.shape)\n",
    "    seed = torch.from_numpy(pred).long().to(device).unsqueeze(0)\n",
    "    del pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1632e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954b9596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
